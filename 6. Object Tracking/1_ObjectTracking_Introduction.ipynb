{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_ObjectTracking_Introduction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP8vFes5mrlOmMsqhBSeUp2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/worklifesg/Python-for-Computer-Vision-with-OpenCV-and-Deep-Learning/blob/main/6.%20Object%20Tracking/1_ObjectTracking_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ3fGAmciSyq"
      },
      "source": [
        "### Object Tracking\r\n",
        "\r\n",
        "In this section, we will cover:\r\n",
        "\r\n",
        "- Basic Object Tracking Techniques\r\n",
        " - Optical Flow\r\n",
        " - Meanshift and Camshift\r\n",
        "- Advanced Tracking\r\n",
        " - Built-In Tracking APIs\r\n",
        "\r\n",
        "#### Optical Flow\r\n",
        "\r\n",
        "- It is defined ss the pattern of apparent motion of image objects between 2 consecutive frames caused by the movement of object or camera.\r\n",
        "- <b> Assumptions: </b>\r\n",
        " - Pixel intensities of object between consecutive frames <b> DONOT CHANGWE </b>\r\n",
        " - Neighbouring pixels have similar motion\r\n",
        "- Methods:\r\n",
        " - Take given set of points and a frame.\r\n",
        " - Attempt to find those points in next frame.\r\n",
        " - Upto user to supply the points to track.\r\n",
        "- We need to also see that in which direction object is moving or is it the camera which is moving.\r\n",
        "-<b> General way to track a object: </b> We will pass <b> previous frame, previous points and current points </b> to the <b> Lucas Kanade </b> function.\r\n",
        "- The function then attempts to locate points in the current frame.\r\n",
        "- <b> Lucas Kanade </b> computes optical flow for a <b> sparse </b> feature set i.e. only points that it was told to track.\r\n",
        " - But to track all points in the video, we have to use <b> Gunner Farneback's algorithm that computes dense optical flow </b>. It will color them black if no flow is detected.\r\n",
        "\r\n",
        "- <b> Optical Flow Equation:</b>\r\n",
        " - Consider an object with intensity $I (x, y, t)$, after time $dt$, it moves to by $dx$ and $dy$, now, the new intensity would be, $I (x+dx, y+dy, t+dt)$.\r\n",
        " - We, assume that the pixel intensities are constant between the two frames, i.e.,\r\n",
        "\\begin{align*}\r\n",
        " I (x, y, t) = I (x+dx, y+dy, t+dt)\r\n",
        "\\end{align*}\r\n",
        "\r\n",
        " - Then take taylor series approximation of right-hand side, resulting in,\r\n",
        "\r\n",
        " \\begin{align*}\r\n",
        " \\dfrac{dI}{dx}\\delta x+\\dfrac{dI}{dy}\\delta y+\\dfrac{dI}{dt}\\delta t=0\r\n",
        " \\end{align*}\r\n",
        "\r\n",
        " - Dividing equation above by $\\delta t $ gives us <b> Optical Flow Equation:</b>\r\n",
        "\r\n",
        " \\begin{align*}\r\n",
        " \\dfrac{dI}{dx}u+\\dfrac{dI}{dy}v+\\dfrac{dI}{dt}=0\r\n",
        " \\end{align*}\r\n",
        "\r\n",
        " - where $u= \\delta x/\\delta t, v= \\delta y/\\delta t$ and $dl/dx$ is image gradient along horizontal axis and $dl/dy$ is image gradient along vertical axis and $dl/dt$ is along the time. \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "#### Lucas - Kanade Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwE1t2flOcWC"
      },
      "source": [
        "import cv2\r\n",
        "import numpy as np\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pHIsw9HpKSe"
      },
      "source": [
        "#Creating a dictionary to track corners\r\n",
        "corner_track_params = dict(maxCorners=10,\r\n",
        "                           qualityLevel=0.3,\r\n",
        "                           minDistance=7,\r\n",
        "                           blockSize=7)\r\n",
        "#parameters for Lucas Kanade function\r\n",
        "#Smaller window - more senstive to noise and may miss larger motions\r\n",
        "'''\r\n",
        "LK method using the idea of image pyramid \r\n",
        "Level0 - original image, Level1 - 1/2 resol, Level2 - 1/4 resol, Level3 - 1/8 resol, Level4 - 1/15 resol\r\n",
        "At each level the image is blurred and subsample i.e. allows to find optical flow at various resolutions\r\n",
        "'''\r\n",
        "lk_params = dict(winSize=(200,200),\r\n",
        "                 maxLevel=2,\r\n",
        "                 criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,10,0.03))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agBAX3Jqrl-5"
      },
      "source": [
        "# live streaming capturing of Sparse Optical Flow\r\n",
        "\r\n",
        "cap = cv2.VideoCapture(0)\r\n",
        "ret,prev_frame = cap.read()\r\n",
        "\r\n",
        "prev_gray = cv2.cvtColor(prev_frame,cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "# points to track\r\n",
        "\r\n",
        "prevPts = cv2.goodFeaturesToTrack(prev_gray,mask=None,**corner_track_params)\r\n",
        "\r\n",
        "#mask\r\n",
        "mask = np.zeros_like(prev_frame)\r\n",
        "\r\n",
        "while True:\r\n",
        "\r\n",
        "  ret, frame = cap.read()\r\n",
        "  frame_gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "  nextPts, status, err = cv2.calcOpticalFlowPyrLK(prev_gray,frame_gray,prevPts, None,**lk_params)\r\n",
        "\r\n",
        "  good_new = nextPts[status==1]\r\n",
        "  good_prev = prevPts[status==1]\r\n",
        "\r\n",
        "  for i, (new,prev), in enumerate(zip(good_new,good_prev)):\r\n",
        "    x_new,y_new = new.ravel()\r\n",
        "    x_prev,y_prev = prev.ravel()\r\n",
        "\r\n",
        "    mask = cv2.line(mask,(x_new,y_new),(x_prev,y_prev),(0,255,0),3)\r\n",
        "\r\n",
        "    frame = cv2.circle(frame,(x_new,y_new),8,(0,0,255),-1) #draing circle on current points in a frame are\r\n",
        "  \r\n",
        "  img = cv2.add(frame,mask)\r\n",
        "  cv2.imshow('tracking',img)\r\n",
        "\r\n",
        "  k = cv2.waitKey(30) & 0xFF\r\n",
        "  if k == 27:\r\n",
        "    break\r\n",
        "  \r\n",
        "  prev_gray = frame_gray.copy()\r\n",
        "  prevPts = good_new.reshape(-1,1,2)\r\n",
        "\r\n",
        "cv2.destroyAllWindows()\r\n",
        "cap.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}