{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pejmanrasti/Computer-Vision/blob/main/Jour_3/TD_ML_5_2_Spotcheck_6_AjustementFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2665898-2c4a-49c3-86fe-16039cc9fbc7",
      "metadata": {
        "id": "c2665898-2c4a-49c3-86fe-16039cc9fbc7"
      },
      "source": [
        "1. D√©finir le probl√®me\n",
        "\n",
        "\n",
        "2. R√©cup√©rer les donn√©es\n",
        "\n",
        "\n",
        "3. Analyser et nettoyer les donn√©es\n",
        "  \n",
        "\n",
        "4. Pr√©parer les donn√©es\n",
        "  \n",
        "\n",
        "5. **Evaluer plusieurs mod√®les**\n",
        "  \n",
        "\n",
        "6. **R√©glage fin des mod√®les**\n",
        "\n",
        "\n",
        "7. Surveiller son mod√®le"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a24a043-941a-4920-9fc6-72d7af1e111a",
      "metadata": {
        "id": "6a24a043-941a-4920-9fc6-72d7af1e111a"
      },
      "source": [
        "# üìå 5. Evaluer plusieurs mod√®les : validation crois√©e"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c08853f-278f-44cb-9c7c-0ac8b8a16167",
      "metadata": {
        "id": "0c08853f-278f-44cb-9c7c-0ac8b8a16167"
      },
      "outputs": [],
      "source": [
        "# Import des biblioth√®ques n√©cessaires\n",
        "import warnings  # Pour √©viter les warnings inutiles\n",
        "\n",
        "import pandas as pd  # Pour la manipulation et l'analyse des donn√©es structur√©es\n",
        "import numpy as np  # Pour les op√©rations num√©riques et le traitement des tableaux\n",
        "import matplotlib.pyplot as plt  # Pour la cr√©ation de graphiques et de visualisations\n",
        "import seaborn as sns  # Pour des visualisations statistiques avanc√©es bas√©es sur Matplotlib\n",
        "\n",
        "# Biblioth√®ques Scikit-learn pour la pr√©paration des donn√©es et le ML\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split, StratifiedKFold, cross_val_score, cross_val_predict, GridSearchCV\n",
        ")  # Pour diviser les donn√©es, validation crois√©e et recherche de grille\n",
        "from sklearn.preprocessing import StandardScaler  # Pour la normalisation des donn√©es\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif  # Pour la s√©lection de variables\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        ")  # Classifieurs bas√©s sur des ensembles d'arbres\n",
        "from sklearn.linear_model import LogisticRegression  # Pour la r√©gression logistique\n",
        "from sklearn.svm import SVC  # Pour les machines √† vecteurs de support\n",
        "from sklearn.neighbors import KNeighborsClassifier  # Pour le classifieur des k plus proches voisins\n",
        "from sklearn.naive_bayes import GaussianNB  # Pour le classifieur Naive Bayes Gaussien\n",
        "from sklearn.neural_network import MLPClassifier  # Pour les r√©seaux de neurones\n",
        "from sklearn.pipeline import Pipeline  # Pour cr√©er des pipelines de traitement\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score, roc_curve, RocCurveDisplay, auc, precision_recall_curve,\n",
        "    average_precision_score, precision_score, recall_score, make_scorer,\n",
        "    accuracy_score, confusion_matrix\n",
        ")  # Pour l'√©valuation des performances du mod√®le\n",
        "from imblearn.under_sampling import RandomUnderSampler  # Pour le sous-√©chantillonnage des donn√©es d√©s√©quilibr√©es\n",
        "\n",
        "from sklearn.datasets import make_classification  # Pour g√©n√©rer des jeux de donn√©es de classification\n",
        "from sklearn.inspection import permutation_importance  # Pour l'importance des variables par permutation\n",
        "\n",
        "import ipywidgets as widgets  # Pour cr√©er des widgets interactifs dans Jupyter\n",
        "from IPython.display import display, clear_output  # Pour afficher et effacer les sorties dans Jupyter\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")  # D√©sactiver les warnings pour ne pas surcharger l'affichage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98dec0c9-0b0f-4a35-b91e-c77f6d89dd96",
      "metadata": {
        "id": "98dec0c9-0b0f-4a35-b91e-c77f6d89dd96"
      },
      "source": [
        "## üîπ5.1. Chargement des donn√©es"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5f1c43-a5a1-489b-ae0e-45dc60f50f2d",
      "metadata": {
        "id": "1e5f1c43-a5a1-489b-ae0e-45dc60f50f2d"
      },
      "source": [
        "<font size = 4> ‚û°Ô∏è **S√©paration des donn√©es en entra√Ænement et test** </font>\n",
        "\n",
        "\n",
        "Nous s√©parons le dataset en :\n",
        "- **70% d'entra√Ænement** pour apprendre au mod√®le.\n",
        "- **30% de test** pour √©valuer ses performances sur des donn√©es jamais vues.\n",
        "\n",
        "<font size = 4> ‚û°Ô∏è **Sous-√©chantillonnage de la classe majoritaire** </font>\n",
        "\n",
        "\n",
        "Nous √©quilibrons la base pour √©viter un d√©s√©quilibre qui pourrait biaiser l'entra√Ænement.\n",
        "\n",
        "<font size = 4> ‚û°Ô∏è **Normalisation des variables** </font>\n",
        "\n",
        "\n",
        "Les mod√®les sensibles aux √©chelles de variables (**SVM, MLP, R√©gression Logistique**) n√©cessitent une normalisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70ad2dff-45e5-4df6-9e7c-90099fdf02e9",
      "metadata": {
        "id": "70ad2dff-45e5-4df6-9e7c-90099fdf02e9"
      },
      "outputs": [],
      "source": [
        "# Chargement des donn√©es\n",
        "df = pd.read_csv(\"/content/DataSet_RegionPelvienne_Class.csv\", sep=\",\")\n",
        "df = df.drop(columns=[\"Unnamed: 0\"])  # Suppression de colonnes inutiles\n",
        "\n",
        "# Aper√ßu des donn√©es\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f649b8e-7f03-41bc-9024-642022299807",
      "metadata": {
        "id": "1f649b8e-7f03-41bc-9024-642022299807"
      },
      "outputs": [],
      "source": [
        "warnings.simplefilter(action='ignore', category=FutureWarning)  # Ignore les FutureWarning\n",
        "\n",
        "# S√©paration des variables explicatives et de la cible\n",
        "y = df['Echec']\n",
        "X = df.drop(columns=['Echec'])\n",
        "\n",
        "# Division des donn√©es en jeu d'entra√Ænement (70%) et de test (30%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=2025)\n",
        "\n",
        "# R√©√©quilibrage des classes dans l'entra√Ænement\n",
        "# On fixe un ratio de 1/3 pour la classe positive et 2/3 pour la classe n√©gative\n",
        "rus = RandomUnderSampler(sampling_strategy={0: len(y_train[y_train == 1]) * 2, 1: len(y_train[y_train == 1])}, random_state=2025)\n",
        "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "# Standardisation des variables explicatives\n",
        "scaler = StandardScaler()\n",
        "X_train_res_std = scaler.fit_transform(X_train_res)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# Conversion en DataFrame pour conserver les noms des colonnes\n",
        "X_train_res_std = pd.DataFrame(X_train_res_std, columns=X_train_res.columns, index=X_train_res.index)\n",
        "X_test_std = pd.DataFrame(X_test_std, columns=X_test.columns, index=X_test.index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f24d6183-59d2-4187-a4eb-5d32184bd963",
      "metadata": {
        "id": "f24d6183-59d2-4187-a4eb-5d32184bd963"
      },
      "source": [
        "## üîπ5.2 Spotcheck\n",
        "\n",
        "<font size = 4>  üîç **Objectif du Spotcheck**   </font>\n",
        "\n",
        "\n",
        "Avant d'optimiser finement un mod√®le de Machine Learning, on peut **tester rapidement plusieurs algorithmes** pour identifier ceux qui ont le plus de potentiel sur un jeu de donn√©es donn√©. Cette approche permet de **gagner du temps** et d'√©viter d'optimiser un mod√®le qui ne conviendrait pas aux donn√©es.\n",
        "\n",
        "<font size = 4>üéØ **Avantages du Spotcheck** </font>  \n",
        "1. **√âvaluation rapide des performances**  \n",
        "   - Permet de comparer plusieurs mod√®les sans r√©glages complexes.  \n",
        "   - Utilisation d'une **validation crois√©e** pour obtenir des r√©sultats robustes.  \n",
        "\n",
        "2. **S√©lection des mod√®les les plus prometteurs**  \n",
        "   - Certains algorithmes peuvent √™tre inadapt√©s √† la structure des donn√©es.  \n",
        "   - On garde uniquement les mod√®les offrant les **meilleures performances initiales**.  \n",
        "\n",
        "3. **√âconomie de ressources**  \n",
        "   - √âviter une recherche exhaustive d‚Äôhyper-param√®tres sur des mod√®les peu performants.  \n",
        "   - R√©duction du **temps de calcul** en ciblant l‚Äôoptimisation sur un sous-ensemble restreint de mod√®les.  \n",
        "\n",
        "<font size = 4>‚ö†Ô∏è **Limites du Spotcheck**  </font>  \n",
        "- Les performances obtenues ne sont **pas d√©finitives** car les mod√®les utilisent leurs param√®tres par d√©faut.  \n",
        "- Un mod√®le qui semble peu performant √† ce stade pourrait s'am√©liorer avec une **optimisation pouss√©e**.  \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d529226-99e9-4d5c-959a-858e4931af02",
      "metadata": {
        "id": "3d529226-99e9-4d5c-959a-858e4931af02"
      },
      "source": [
        "<img src=\"https://www.sharpsightlabs.com/wp-content/uploads/2024/02/5-fold-cross-validation_SIMPLE-EXAMPLE_v2.png\" alt=\"drawing\" width=\"700\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49859ad0-545a-425f-a487-0c110abc61be",
      "metadata": {
        "id": "49859ad0-545a-425f-a487-0c110abc61be"
      },
      "outputs": [],
      "source": [
        "# D√©finition des mod√®les √† tester\n",
        "models_base = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=10000, random_state=2025),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=2025),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=2025),\n",
        "    \"AdaBoost\": AdaBoostClassifier(random_state=2025),\n",
        "    \"SVM\": SVC(kernel=\"linear\", probability=True, random_state=2025),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"MLP Classifier\": MLPClassifier(learning_rate = 'adaptive', solver = 'adam', max_iter=10000, random_state=2025)\n",
        "}\n",
        "\n",
        "# D√©finition de la validation crois√©e : 5 folds stratifi√©s\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=2025)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a465f6aa-60ef-4110-8a8c-1bf338621cc1",
      "metadata": {
        "id": "a465f6aa-60ef-4110-8a8c-1bf338621cc1"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# Fixer la graine al√©atoire pour garantir la reproductibilit√©\n",
        "np.random.seed(2025)\n",
        "\n",
        "# Stockage des scores\n",
        "results = {}\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# √âvaluation de chaque mod√®le avec cross-validation\n",
        "for name, model in models_base.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),  # Normalisation des donn√©es\n",
        "        ('feature_selection', SelectKBest(score_func=mutual_info_classif, k=30)),  # S√©lection des variables\n",
        "        ('classifier', model)  # Mod√®le de classification\n",
        "    ])\n",
        "\n",
        "    # Cross-validation en utilisant l'AUC-ROC comme m√©trique\n",
        "    scores = cross_val_score(pipeline, X_train_res, y_train_res, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
        "    results[name] = scores.mean()  # Moyenne des scores obtenus\n",
        "\n",
        "    # Pr√©dictions pour le calcul de la courbe ROC (cross_val_predict avec la m√©thode predict_proba retourne les probabilit√©s pr√©dite pour chaque fold de validation de la CV)\n",
        "    y_scores = cross_val_predict(pipeline, X_train_res, y_train_res, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "    fpr, tpr, _ = roc_curve(y_train_res, y_scores)\n",
        "\n",
        "    # Affichage de la courbe ROC pour chaque mod√®le\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUC = {scores.mean():.2f})\")\n",
        "\n",
        "# Ajout d'une ligne diagonale pour le classifieur al√©atoire\n",
        "plt.plot([0, 1], [0, 1], linestyle='--', color='grey', label=\"Classifieur Al√©atoire\")\n",
        "\n",
        "# Mise en forme de la courbe ROC\n",
        "plt.xlabel(\"Taux de Faux Positifs (FPR)\")\n",
        "plt.ylabel(\"Taux de Vrais Positifs (TPR)\")\n",
        "plt.title(\"Courbes ROC des Mod√®les\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e31140cc-72fc-451a-bb8d-2e1852fa07d7",
      "metadata": {
        "id": "e31140cc-72fc-451a-bb8d-2e1852fa07d7"
      },
      "outputs": [],
      "source": [
        "# Affichage des r√©sultats sous forme de DataFrame\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index', columns=[\"AUC-ROC\"])\n",
        "\n",
        "# Arrondi des valeurs √† 2 chiffres significatifs\n",
        "results_df[\"AUC-ROC\"] = results_df[\"AUC-ROC\"].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "# Tri des r√©sultats par ordre d√©croissant d'AUC-ROC\n",
        "results_df = results_df.sort_values(by=\"AUC-ROC\", ascending=False)\n",
        "\n",
        "# Affichage des r√©sultats\n",
        "print(\"\\nüìä R√©sultats du Spotcheck (AUC-ROC moyen sur CV) :\")\n",
        "print(results_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cccfcb08-4f00-49cd-8a6a-4e94d2866281",
      "metadata": {
        "id": "cccfcb08-4f00-49cd-8a6a-4e94d2866281"
      },
      "source": [
        "## üîπ 5.3. Hyperparam√®tres et optimisation\n",
        "<font size = 4> ‚û°Ô∏è <span style=\"color:#3498db \">**Qu'est-ce qu'un hyper-param√®tre ?** </span></font>\n",
        "\n",
        "\n",
        "Un **hyper-param√®tre** est une valeur d√©finie **avant l'entra√Ænement d'un mod√®le** et qui contr√¥le le processus d'apprentissage. Contrairement aux **param√®tres internes** (comme les poids dans une r√©gression ou les n≈ìuds d‚Äôun arbre de d√©cision), **les hyper-param√®tres ne sont pas appris automatiquement** par l‚Äôalgorithme, mais doivent √™tre choisis par l'utilisateur.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f177684f-0919-4da2-930b-bf418cfa24d3",
      "metadata": {
        "id": "f177684f-0919-4da2-930b-bf418cfa24d3"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "<font size = 4> ‚û°Ô∏è <span style=\"color:#3498db \">**Diff√©rence entre hyper-param√®tres et param√®tres internes** </span>  </font>\n",
        "\n",
        "\n",
        "| Type | D√©finition | Exemples |\n",
        "|------|------------|----------|\n",
        "| **Hyper-param√®tres** | Choix d√©finis avant l'entra√Ænement qui influencent la mani√®re dont le mod√®le apprend | - `C` dans une r√©gression logistique (force de la r√©gularisation) <br> - `n_estimators` dans une For√™t Al√©atoire (nombre d'arbres) <br> - `learning_rate` dans un Gradient Boosting (taux d'apprentissage) |\n",
        "| **Param√®tres internes** | Valeurs apprises automatiquement √† partir des donn√©es | - Les coefficients (`coef_`) dans une r√©gression logistique <br> - Les seuils de d√©cision d'un arbre <br> - Les poids des neurones dans un r√©seau de neurones |\n",
        "\n",
        "<font size = 4> ‚û°Ô∏è <span style=\"color:#3498db \">**Exemples d'hyper-param√®tres par algorithme**   </span></font>\n",
        "\n",
        "\n",
        "- **R√©gression Logistique** : `C` (contr√¥le la r√©gularisation), `penalty` (choix entre L1/L2)\n",
        "- **SVM (Support Vector Machine)** : `kernel` (lin√©aire, RBF...), `C` (r√©gularisation), `gamma` (influence d‚Äôun point)\n",
        "- **For√™t Al√©atoire** : `n_estimators` (nombre d'arbres), `max_depth` (profondeur max des arbres)\n",
        "- **R√©seaux de Neurones** : `hidden_layer_sizes` (nombre de neurones cach√©s), `learning_rate` (taux d‚Äôapprentissage)\n",
        "\n",
        "<font size = 4> ‚û°Ô∏è <span style=\"color:#3498db \">**Pourquoi les hyper-param√®tres sont-ils importants ?**  </span> </font>\n",
        "\n",
        "\n",
        "Le choix des **hyper-param√®tres influence directement la performance du mod√®le** :\n",
        "- **Trop de complexit√©** ‚Üí risque de **sur-apprentissage** (overfitting) = bon sur l'entra√Ænement, mauvais sur les nouvelles donn√©es.\n",
        "- **Pas assez de complexit√©** ‚Üí risque de **sous-apprentissage** (underfitting) = le mod√®le ne capture pas assez bien les tendances.\n",
        "\n",
        "<font size = 4> ‚û°Ô∏è <span style=\"color:#3498db \">**Comment optimiser les hyper-param√®tres ?**   </span></font>\n",
        "\n",
        "\n",
        "Les hyper-param√®tres doivent √™tre **optimis√©s** pour maximiser les performances du mod√®le. Plusieurs techniques existent :\n",
        "- **Recherche sur grille (`GridSearchCV`)** : teste toutes les combinaisons possibles dans un espace d√©fini.\n",
        "- **Recherche al√©atoire (`RandomizedSearchCV`)** : teste un nombre limit√© de combinaisons s√©lectionn√©es al√©atoirement.\n",
        "- **Optimisation bay√©sienne** : trouve progressivement les meilleures valeurs en fonction des r√©sultats pr√©c√©dents (avec `BayesSearchCV` issue de la librairie `Scikit-Optimize`).\n",
        "- **Succesive Halving (`HalvingGridSearchCV` et `HalvingRandomSearchCV`)** : teste les combinaisons d‚Äôhyperparam√®tres avec une allocation progressive des ressources (donn√©es et it√©rations).\n",
        "\n",
        "Les hyper-param√®tres sont optimis√©s via une CV en se basant sur un **score**. La plupart du temps on peut utiliser ceux d√©finis dans la biblioth√®que `metrics` de Scikit comme 'roc_auc', 'recall', 'precision' üîó [Documentation Scikit - Metriques]( https://scikit-learn.org/stable/modules/model_evaluation.html#string-name-scorers)     \n",
        "On peut aussi cr√©er sa **propre m√©trique** de performance qui sera utilis√©e pendant la CV.    \n",
        "Pour cela il faut respecter les r√®gles √©dit√©es par Sklearn : üîó [Documentation Scikit - MetriquePerso](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-callable)   \n",
        "\n",
        "Exemple :\n",
        "````python\n",
        "def AUPRC(clf, X, y_true):   \n",
        "    y_pred_proba = clf.predict_proba(X)   \n",
        "    precision, recall, _ = precision_recall_curve(y_true, y_pred_proba[:, 1])   \n",
        "    auc_score = metrics.auc(recall, precision)   \n",
        "    return (auc_score)\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1640bdf1-c889-4c83-8b50-9772b010460b",
      "metadata": {
        "id": "1640bdf1-c889-4c83-8b50-9772b010460b"
      },
      "source": [
        "<img src=\"https://www.researchgate.net/publication/364680393/figure/fig2/AS:11431281092692424@1666930838216/Tuning-of-hyperparameters-using-fivefold-cross-validation-GridSearchCV.png\" alt=\"drawing\" width=\"800\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a15d468e-b7e4-4440-8bd3-463b13261cda",
      "metadata": {
        "id": "a15d468e-b7e4-4440-8bd3-463b13261cda"
      },
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*Xq9OvMKXhrF3W2RBJCWW7w.png\" alt=\"drawing\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa1f0e8d-5a1e-4317-a9f2-12ddbc3644ff",
      "metadata": {
        "id": "fa1f0e8d-5a1e-4317-a9f2-12ddbc3644ff"
      },
      "source": [
        "<font size = 4> ‚û°Ô∏è **On s√©lectionne les 5 algorithmes les plus prometteurs :** </font>\n",
        "- Random forest\n",
        "- Gradient Boosting\n",
        "- SVM\n",
        "- Logistic Regression\n",
        "- MLP Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6731359-3857-4e75-89cb-9cb679c66788",
      "metadata": {
        "id": "c6731359-3857-4e75-89cb-9cb679c66788"
      },
      "source": [
        "<font size = 4> <span style=\"color:#2980b9\">üå≥ **Impact des hyper-param√®tres sur les performances : Exemple avec Random Forest** </span></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a43edd05-64b4-4179-9e20-ded997d18b76",
      "metadata": {
        "id": "a43edd05-64b4-4179-9e20-ded997d18b76"
      },
      "source": [
        "<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*b3kM3WFJB6b92ZHp_J871Q.jpeg\" alt=\"drawing\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "325d8582-dc6c-462b-bf77-935fe1d0f7cd",
      "metadata": {
        "id": "325d8582-dc6c-462b-bf77-935fe1d0f7cd"
      },
      "source": [
        "Une **for√™t al√©atoire** (Random Forest) est un **algorithme d'apprentissage supervis√©** bas√© sur un ensemble d'arbres de d√©cision. Il fonctionne selon le principe suivant :\n",
        "\n",
        "1. **Cr√©ation de plusieurs arbres de d√©cision** √† partir d'√©chantillons al√©atoires des donn√©es d'entra√Ænement (**bootstrap sampling**).\n",
        "2. **Pr√©diction par vote majoritaire** (pour la classification) ou **moyenne des pr√©dictions** (pour la r√©gression).\n",
        "\n",
        "\n",
        "| Hyper-param√®tre | Description |\n",
        "|---------------|------------|\n",
        "| `n_estimators` | Nombre d'arbres dans la for√™t |\n",
        "| `max_depth` | Profondeur maximale des arbres |\n",
        "| `min_samples_split` | Nombre minimum d‚Äô√©chantillons pour diviser un n≈ìud |\n",
        "| `min_samples_leaf` | Nombre minimum d‚Äô√©chantillons par feuille |\n",
        "| `max_features` | Nombre de variables test√©es √† chaque division |\n",
        "| `bootstrap` | Utilisation d‚Äô√©chantillons al√©atoires avec remise pour construire chaque arbre |\n",
        "| `class_weight` | Poids des classes (utile pour donn√©es d√©s√©quilibr√©es) |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2b96064-fb63-48a0-965d-84a9e82b1cae",
      "metadata": {
        "id": "e2b96064-fb63-48a0-965d-84a9e82b1cae"
      },
      "source": [
        "<font size = 3>‚û°Ô∏è **On teste l'impact de 3 hyper-param√®tres, pris ind√©pendamment, sur les performances de la for√™t al√©atoire mesur√©es avec l'AUROC :** </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e40e9d-39e6-4383-8cbd-34bef33cc14a",
      "metadata": {
        "id": "15e40e9d-39e6-4383-8cbd-34bef33cc14a"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Fixer la graine al√©atoire pour garantir la reproductibilit√©\n",
        "np.random.seed(2025)\n",
        "\n",
        "# D√©finition du mod√®le de base\n",
        "rf = RandomForestClassifier(random_state=2025, n_jobs=-1)\n",
        "\n",
        "# D√©finition de la validation crois√©e\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=2025)\n",
        "\n",
        "# D√©finition des hyper-param√®tres √† tester\n",
        "param_grids = {\n",
        "    \"n_estimators\": [3, 5, 7, 10, 12, 14, 16, 20, 25, 30, 35, 40, 45,  50, 70, 100],  # Nombre d'arbres\n",
        "    \"max_depth\": [2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20],  # Profondeur max\n",
        "    \"min_samples_split\": [2, 3, 4, 5,6, 7, 8, 9, 10, 15, 17, 20]  # Nombre minimum d'√©chantillons pour diviser un n≈ìud\n",
        "}\n",
        "\n",
        "# Stockage des r√©sultats\n",
        "results = {}\n",
        "\n",
        "# Recherche sur grille pour chaque hyper-param√®tre\n",
        "for param, values in param_grids.items():\n",
        "    print(f\"Optimisation de {param}...\")\n",
        "\n",
        "    grid = GridSearchCV(\n",
        "        rf,\n",
        "        param_grid={param: values},\n",
        "        cv=cv,\n",
        "        scoring=\"roc_auc\",\n",
        "        n_jobs=-1,\n",
        "        return_train_score=False\n",
        "    )\n",
        "\n",
        "    # Entra√Ænement sur l'ensemble des donn√©es d'entra√Ænement\n",
        "    grid.fit(X_train_res_std, y_train_res)\n",
        "\n",
        "    # Stockage des r√©sultats\n",
        "    results[param] = {\n",
        "        \"values\": values,\n",
        "        \"mean_score\": grid.cv_results_[\"mean_test_score\"],\n",
        "        \"std_score\": grid.cv_results_[\"std_test_score\"]\n",
        "    }\n",
        "\n",
        "# Trac√© des courbes AUROC pour chaque hyper-param√®tre\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "for i, (param, res) in enumerate(results.items()):\n",
        "    plt.subplot(1, 3, i + 1)\n",
        "    plt.plot(res[\"values\"], res[\"mean_score\"], 'o-', label=\"AUROC moyen\")\n",
        "    plt.fill_between(\n",
        "        res[\"values\"],\n",
        "        np.array(res[\"mean_score\"]) - np.array(res[\"std_score\"]),\n",
        "        np.array(res[\"mean_score\"]) + np.array(res[\"std_score\"]),\n",
        "        alpha=0.2, label=\"√âcart-type\"\n",
        "    )\n",
        "    plt.xlabel(param)\n",
        "    plt.ylabel(\"AUROC\")\n",
        "    plt.ylim(0.7, 0.95)\n",
        "    plt.title(f\"Effet de {param} sur AUROC\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61dd1004-5ff3-4684-b683-5059c36af834",
      "metadata": {
        "id": "61dd1004-5ff3-4684-b683-5059c36af834"
      },
      "source": [
        "<font size = 4> <span style=\"color:#2980b9\"> üìà **Impact de la m√©trique de performance sur le choix des hyper-param√®tres : Exemple avec la r√©gression logistique** </span> </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a04883ab-5cc4-42ff-853c-38071e052a0e",
      "metadata": {
        "id": "a04883ab-5cc4-42ff-853c-38071e052a0e"
      },
      "source": [
        "<img src=\"https://datatab.fr/assets/tutorial/Logistic-function.png\" alt=\"drawing\" width=\"400\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f57729ce-befa-4184-a413-38fca5da91c4",
      "metadata": {
        "id": "f57729ce-befa-4184-a413-38fca5da91c4"
      },
      "source": [
        "La **r√©gression logistique** comporte trois principaux hyper-param√®tres : le type de r√©gularisation `penalty`, la force de la r√©gularisation `C` et le `solver` (l'algorithme utilis√© pour minimiser la fonction co√ªt - qui quantifie l'erreur entre les pr√©dictions et les valeurs r√©elles -  en ajustant les poids du mod√®le de mani√®re it√©rative).   \n",
        "> La **r√©gularisation** permet de limiter le **sur-apprentissage** (overfitting) en limitant la complexit√© du mod√®le. En effet, plus un mod√®le est complexe plus il risque d'avoir appris *par coeur* les donn√©es d'entrainement au lieu d'avoir appris *√† partir* des donn√©es d'entrainement et donc il risque d'√™tre mauvais sur de nouvelles donn√©es (mauvaise g√©n√©ralisation). Un terme de r√©gularisation est donc ajout√© √† la fonction co√ªt du mod√®le (dont le type est souvent d√©sign√© par l'hyper-param√®tre \"Penalty\" et la force par l'hyper-param√®tre \"C\") afin de r√©duire ses degr√©s de libert√© (par exemple imposer des contraintes sur le poids des coefficients pour un mod√®le lin√©aire).    \n",
        "Les diff√©rents types de r√©gularisation sont :\n",
        ">- l1 (ou Lasso pour Least Absolute Shrinkage and Selection Operator) :  diminue le nombre de variables du mod√®le\n",
        ">- l2 (ou Ridge) : limite le poids des variables\n",
        ">- ElasticNet : combinaison de l1 et l2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "827cd107-9084-4577-ae7a-d22ffa1e4a11",
      "metadata": {
        "id": "827cd107-9084-4577-ae7a-d22ffa1e4a11"
      },
      "outputs": [],
      "source": [
        "\n",
        "# D√©finition du mod√®le\n",
        "lr = LogisticRegression(max_iter=1000, random_state=2025)\n",
        "\n",
        "# D√©finition de la validation crois√©e\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=2025)\n",
        "\n",
        "# D√©finition des valeurs de C √† tester\n",
        "param_grid = {\"C\": np.arange(0.01,1,0.05)}\n",
        "\n",
        "# D√©finition des m√©triques utilis√©es\n",
        "scoring_metrics = {\n",
        "    \"AUROC\": make_scorer(roc_auc_score),\n",
        "    \"Accuracy\": make_scorer(accuracy_score),\n",
        "}\n",
        "\n",
        "# Recherche des hyperparam√®tres via GridSearchCV\n",
        "grid = GridSearchCV(\n",
        "    lr,\n",
        "    param_grid=param_grid,\n",
        "    cv=cv,\n",
        "    scoring=scoring_metrics,\n",
        "    n_jobs=-1,\n",
        "    return_train_score=False,\n",
        "    refit=\"AUROC\"  # Optimisation par d√©faut sur AUROC\n",
        ")\n",
        "\n",
        "# Entra√Ænement sur l'ensemble des donn√©es d'entra√Ænement\n",
        "grid.fit(X_train_res_std, y_train_res)\n",
        "\n",
        "# Stockage des r√©sultats\n",
        "results = {\n",
        "    \"values\": param_grid[\"C\"],\n",
        "    \"mean_AUROC\": grid.cv_results_[\"mean_test_AUROC\"],\n",
        "    \"std_AUROC\": grid.cv_results_[\"std_test_AUROC\"],\n",
        "    \"mean_Accuracy\": grid.cv_results_[\"mean_test_Accuracy\"],\n",
        "    \"std_Accuracy\": grid.cv_results_[\"std_test_Accuracy\"],\n",
        "}\n",
        "\n",
        "# Trac√© des courbes pour l'hyperparam√®tre C\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Affichage de l'AUROC\n",
        "plt.plot(results[\"values\"], results[\"mean_AUROC\"], 'o-', label=\"AUROC\", color=\"blue\")\n",
        "plt.fill_between(\n",
        "    results[\"values\"],\n",
        "    np.array(results[\"mean_AUROC\"]) - np.array(results[\"std_AUROC\"]),\n",
        "    np.array(results[\"mean_AUROC\"]) + np.array(results[\"std_AUROC\"]),\n",
        "    alpha=0.2, color=\"blue\"\n",
        ")\n",
        "\n",
        "# Affichage de l'Accuracy\n",
        "plt.plot(results[\"values\"], results[\"mean_Accuracy\"], 's-', label=\"Accuracy\", color=\"green\")\n",
        "plt.fill_between(\n",
        "    results[\"values\"],\n",
        "    np.array(results[\"mean_Accuracy\"]) - np.array(results[\"std_Accuracy\"]),\n",
        "    np.array(results[\"mean_Accuracy\"]) + np.array(results[\"std_Accuracy\"]),\n",
        "    alpha=0.2, color=\"green\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Trouver le meilleur C pour chaque m√©trique\n",
        "for metric, color in zip([\"AUROC\", \"Accuracy\"], [\"blue\", \"green\"]):\n",
        "    best_index = np.argmax(results[f\"mean_{metric}\"])\n",
        "    best_value = results[\"values\"][best_index]\n",
        "    best_score = results[f\"mean_{metric}\"][best_index]\n",
        "\n",
        "    # Ajout d'une ligne verticale pointill√©e et d'une croix pour le meilleur score\n",
        "    plt.axvline(x=best_value, color=color, linestyle=\"--\", alpha=0.7)\n",
        "    plt.plot(best_value, best_score, marker=\"x\", markersize=10, color=color, markeredgewidth=3)\n",
        "    plt.annotate(f\"{best_score:.2f}\", (best_value, best_score + 0.005), fontsize=10, color=color)\n",
        "\n",
        "# Param√®tres d'affichage\n",
        "plt.xlabel(\"Valeur de C (√©chelle logarithmique)\")\n",
        "#plt.xscale(\"log\")  # On met l'axe des X en √©chelle logarithmique pour mieux voir l'effet de C\n",
        "plt.ylabel(\"Score\")\n",
        "plt.ylim(0.5, 1)\n",
        "plt.title(\"Impact de C sur les scores pour la R√©gression Logistique\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "910e0313-b60b-4625-8b56-e146d007a93a",
      "metadata": {
        "id": "910e0313-b60b-4625-8b56-e146d007a93a"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Application </b> Afficher les performances pour des algo pour diff√©rents hyper-param√®tres : </div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b61508-e000-4e52-82e3-aef12e47f034",
      "metadata": {
        "id": "84b61508-e000-4e52-82e3-aef12e47f034"
      },
      "outputs": [],
      "source": [
        "# Fixer la graine al√©atoire pour garantir la reproductibilit√©\n",
        "np.random.seed(2025)\n",
        "\n",
        "# D√©finition des mod√®les disponibles\n",
        "models_test = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=2025, n_jobs=-1),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=2025),\n",
        "    \"SVM\": SVC(probability=True, random_state=2025),\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=10000, random_state=2025),\n",
        "    \"MLP Classifier\": MLPClassifier(max_iter=500, random_state=2025)\n",
        "}\n",
        "\n",
        "# D√©finition des hyper-param√®tres num√©riques pour chaque mod√®le\n",
        "param_options = {\n",
        "    \"Random Forest\": {\n",
        "        \"n_estimators\": (10, 300, 10),\n",
        "        \"max_depth\": (2, 100, 5),\n",
        "        \"min_samples_split\": (2, 50, 2),\n",
        "        \"max_features\": (1, X_train_res_std.shape[1], 1),\n",
        "        \"min_samples_leaf\": (1, 50, 1),\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        \"n_estimators\": (10, 300, 10),\n",
        "        \"learning_rate\": (0.01, 1.0, 0.1),\n",
        "        \"max_depth\": (2, 100, 5),\n",
        "        \"min_samples_split\": (2, 50, 2),\n",
        "        \"min_samples_leaf\": (1, 50, 1),\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        \"C\": (0.01, 5, 0.1),\n",
        "        \"gamma\": (0.01, 1, 0.1),\n",
        "    },\n",
        "    \"Logistic Regression\": {\n",
        "        \"C\": (0.01, 1, 0.01),\n",
        "    },\n",
        "    \"MLP Classifier\": {\n",
        "        \"hidden_layer_sizes\": (10, 200, 10),\n",
        "        \"alpha\": (0.01, 0.1, 0.01),\n",
        "        \"learning_rate_init\": (0.01, 1, 0.1),\n",
        "        \"max_iter\": (100, 1000, 50),\n",
        "    }\n",
        "}\n",
        "\n",
        "# S√©lection du mod√®le\n",
        "model_select = widgets.Dropdown(\n",
        "    options=models_test.keys(),\n",
        "    value=\"Random Forest\",\n",
        "    description=\"Mod√®le\"\n",
        ")\n",
        "\n",
        "# S√©lection des hyper-param√®tres\n",
        "param_select = widgets.SelectMultiple(\n",
        "    options=list(param_options[\"Random Forest\"].keys()),\n",
        "    value=[\"n_estimators\"],\n",
        "    description=\"Param√®tres\"\n",
        ")\n",
        "\n",
        "# Mise √† jour des hyper-param√®tres lorsque l'utilisateur change de mod√®le\n",
        "def update_params(*args):\n",
        "    param_select.options = list(param_options[model_select.value].keys())\n",
        "    param_select.value = list(param_options[model_select.value].keys())[:1]  # S√©lection d'un hyper-param√®tre par d√©faut\n",
        "\n",
        "model_select.observe(update_params, names='value')\n",
        "\n",
        "# Bouton pour lancer l'optimisation\n",
        "button = widgets.Button(description=\"Lancer l'optimisation\")\n",
        "\n",
        "# Zone de sortie pour l'affichage des r√©sultats\n",
        "output = widgets.Output()\n",
        "\n",
        "# Fonction de test des hyper-param√®tres\n",
        "def optimize_params(b):\n",
        "    with output:\n",
        "        clear_output(wait=True)  # Efface l'affichage pr√©c√©dent\n",
        "\n",
        "        selected_model_name = model_select.value\n",
        "        selected_model = models_test[selected_model_name]\n",
        "        selected_params = {param: param_options[selected_model_name][param] for param in param_select.value}\n",
        "        results = {}\n",
        "\n",
        "        print(f\"Optimisation du mod√®le {selected_model_name}...\")\n",
        "\n",
        "        # Recherche sur grille pour chaque hyper-param√®tre s√©lectionn√©\n",
        "        for param, (min_val, max_val, step) in selected_params.items():\n",
        "            values = np.arange(min_val, max_val + step, step)\n",
        "            print(f\"Optimisation de {param} sur {len(values)} valeurs...\")\n",
        "\n",
        "            grid = GridSearchCV(\n",
        "                selected_model,\n",
        "                param_grid={param: values},\n",
        "                cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=2025),\n",
        "                scoring=\"roc_auc\",\n",
        "                n_jobs=-1,\n",
        "                return_train_score=False\n",
        "            )\n",
        "\n",
        "            # Entra√Ænement sur l'ensemble des donn√©es d'entra√Ænement\n",
        "            grid.fit(X_train_res_std, y_train_res)\n",
        "\n",
        "            # Stockage des r√©sultats\n",
        "            results[param] = {\n",
        "                \"values\": values,\n",
        "                \"mean_score\": grid.cv_results_[\"mean_test_score\"],\n",
        "                \"std_score\": grid.cv_results_[\"std_test_score\"]\n",
        "            }\n",
        "\n",
        "        # Trac√© des courbes AUROC\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        for i, (param, res) in enumerate(results.items()):\n",
        "            plt.subplot(1, len(results), i + 1)\n",
        "            plt.plot(res[\"values\"], res[\"mean_score\"], 'o-', label=\"AUROC moyen\")\n",
        "            plt.fill_between(\n",
        "                res[\"values\"],\n",
        "                np.array(res[\"mean_score\"]) - np.array(res[\"std_score\"]),\n",
        "                np.array(res[\"mean_score\"]) + np.array(res[\"std_score\"]),\n",
        "                alpha=0.2, label=\"√âcart-type\"\n",
        "            )\n",
        "            plt.xlabel(param)\n",
        "            plt.ylabel(\"AUROC\")\n",
        "            plt.ylim(0.6, 1)\n",
        "            plt.title(f\"Effet de {param} sur AUROC\")\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "# Lier la fonction au bouton\n",
        "button.on_click(optimize_params)\n",
        "\n",
        "# Affichage des widgets\n",
        "display(model_select, param_select, button, output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f42480dd-4bef-435f-8c09-497e4526f9e6",
      "metadata": {
        "id": "f42480dd-4bef-435f-8c09-497e4526f9e6"
      },
      "source": [
        "# üìå 6. Ajustement des mod√®les les plus prometteurs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20cd8925-b2c6-4690-8f0c-29268551366f",
      "metadata": {
        "id": "20cd8925-b2c6-4690-8f0c-29268551366f"
      },
      "source": [
        "<font size = 3> **Impact combin√© des hyper-param√®tres sur les performances d‚Äôun mod√®le**  </font>\n",
        "\n",
        "\n",
        "Lorsqu'on ajuste un mod√®le, chaque hyper-param√®tre influence diff√©remment la mani√®re dont le mod√®le apprend √† partir des donn√©es. Cependant, ce n‚Äôest pas seulement l‚Äôeffet individuel de chaque hyper-param√®tre qui importe, mais la combinaison de plusieurs hyper-param√®tres.\n",
        "\n",
        "<font size = 3>**Pourquoi la combinaison des hyper-param√®tres est-elle importante ?**  </font>\n",
        "\n",
        "\n",
        "‚úÖ **Interactions complexes** : Un hyper-param√®tre peut bien fonctionner avec une certaine valeur d‚Äôun autre hyper-param√®tre, mais pas ind√©pendamment.   \n",
        "‚úÖ **Effet de compensation** : Un hyper-param√®tre peut r√©duire l'impact n√©gatif d'un autre.   \n",
        "‚úÖ **√âquilibre entre biais et variance** : Certains hyper-param√®tres affectent le biais du mod√®le (ex: r√©gularisation trop forte), d‚Äôautres la variance (ex: nombre d‚Äôarbres en random forest).   \n",
        "\n",
        "<font size = 5>üí°</font> <font size = 3>C‚Äôest pourquoi il faut faire une **recherche combin√©e** des hyper-param√®tres via une cross-validation, plut√¥t que de les optimiser un par un.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7e08679-dc27-4237-b5b6-0dcb5e329bf4",
      "metadata": {
        "id": "a7e08679-dc27-4237-b5b6-0dcb5e329bf4"
      },
      "source": [
        "##  üîπ 6.1 D√©finition des mod√®les et des grilles de recherche\n",
        "\n",
        "On utilise pour cela un dictionnaire python\n",
        "\n",
        "<img src=\"https://dotnettrickscloud.blob.core.windows.net/img/python/2820230312012106.webp\" alt=\"drawing\" width=\"300\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8664b190-38ab-46e0-8bcc-af379b92263b",
      "metadata": {
        "id": "8664b190-38ab-46e0-8bcc-af379b92263b"
      },
      "outputs": [],
      "source": [
        "# D√©finition des mod√®les avec leurs grilles d'hyper-param√®tres\n",
        "# On va utiliser un pipeline par la suite\n",
        "# En pr√©fixant les hyperparam√®tres par clf__, on indique √† GridSearchCV que ces hyperparam√®tres appartiennent au classifieur et non √† d‚Äôautres √©tapes du pipeline.\n",
        "# Evidemment il faut nommer le classifieur \"clf\" lorsqu'on cr√©e le pipeline.\n",
        "models = {\n",
        "    \"Random Forest\": {\n",
        "        \"model\": RandomForestClassifier(criterion = 'gini', max_features = 'sqrt', class_weight = \"balanced\", random_state=2025),\n",
        "        \"params\": {\n",
        "            \"clf__n_estimators\": [100, 120, 150],\n",
        "            \"clf__max_depth\": [6, 8, 10, 12],\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"MLP Classifier\": {\n",
        "        \"model\": MLPClassifier(max_iter=10000, learning_rate = 'adaptive', solver = 'adam', random_state=2025),\n",
        "        \"params\": {\n",
        "            \"clf__hidden_layer_sizes\": [(10,), (20,), (40,), (100,)],\n",
        "            \"clf__alpha\": [0.0001, 0.001, 0.01, 0.1],\n",
        "            \"clf__activation\":  ['tanh', 'relu']\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"SVM\": {\n",
        "        \"model\": SVC(class_weight = \"balanced\", probability=True, random_state=2025),\n",
        "        \"params\": {\n",
        "            \"clf__C\": [0.1, 0.2, 0.5],\n",
        "            \"clf__kernel\": [\"linear\", \"rbf\"]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"Logistic Regression\": {\n",
        "        \"model\": LogisticRegression(class_weight = \"balanced\",max_iter=10000, random_state=2025),\n",
        "        \"params\": {\n",
        "            \"clf__C\": [0.05, 0.1, 0.5, 0.8, 1],\n",
        "            \"clf__solver\": [\"lbfgs\", \"liblinear\", \"saga\"]\n",
        "        }\n",
        "    },\n",
        "\n",
        "    \"Gradient Boosting\": {\n",
        "        \"model\": GradientBoostingClassifier(max_features = 'sqrt', learning_rate = 0.05, min_samples_leaf = 0.1, random_state=2025),\n",
        "        \"params\": {\n",
        "            \"clf__n_estimators\": [80, 100, 150],\n",
        "            \"clf__subsample\" : [0.7, 1.0],\n",
        "            \"clf__min_samples_split\":[2, 4, 6],\n",
        "            \"clf__max_depth\": [3, 6, 8]\n",
        "\n",
        "        }\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed914c7-509c-4f2c-9419-bbd3ec5cf9ac",
      "metadata": {
        "id": "eed914c7-509c-4f2c-9419-bbd3ec5cf9ac"
      },
      "source": [
        "## üîπ 6.2  Recherche des meilleurs hyper-param√®tres"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f931472f-ade5-4196-9b41-b701bfdb195f",
      "metadata": {
        "id": "f931472f-ade5-4196-9b41-b701bfdb195f"
      },
      "source": [
        "Les param√®tres de la **recherche sur grille** :\n",
        "- **estimator** : le mod√®le √† ajuster. Ici on utilise le pipeline qui int√®gre la normalisation des donn√©es. Il faut donc utiliser en entr√©e de ce pipeline les donn√©es **non** normalis√©es. Cela permet de rendre les folds de validation de la CV compl√®tement ind√©pendants √† l'image de donn√©es totalement nouvelles, car les donn√©es normalis√©es sur les folds de validation le sont par rapport √† la moyenne et l'√©cart-type calcul√©s sur les folds d'entrainement gr√¢ce √† la d√©finition de ce pipeline.\n",
        "- **param_grid** : les hyper-param√®tres √† tester\n",
        "- **return_train_score** : est-ce qu'on demande √† connaitre les scores obtenus sur les folds d'entrainement. Cela peut √™tre int√©ressant si on veut estimer l'impact des hyper-param√®tres sur la g√©n√©ralisation du mod√®le mais √ßa requiert √©galement des temps de calcul plus longs.\n",
        "- **cv** : les param√®tres de cross-validation qui va √™tre utilis√©e pour √©valuer les performances du mod√®le. La CV est r√©p√©t√©e autant de fois qu'il y a de combinaisons d'hyper-param√®tres √† tester. Un score moyen sur l'ensemble des folds de validation est obtenu pour chaque combinaison d'hyper-param√®tres test√©e.\n",
        "- **scoring** : la ou les m√©triques √† calculer sur les folds de test. Si on veut calculer plusieurs m√©triques pendant la CV, il faut les d√©finir dans un dictionnaire.\n",
        "- **refit** : puisqu'on donne une liste de m√©triques √† calculer, il faut pr√©ciser quelle m√©trique parmi celles fournies la fonction doit utiliser pour s√©lectionner la meilleure combinaison d'hyper-param√®tres. C'est avec cette combinaison d'hyper-param√®tres que la fonction va r√©entrainer le mod√®le final sur l'ensemble des donn√©es d'entrainements (sans fold de validation).\n",
        "- **error_score** : on demande √† g√©n√©rer une erreur et non √† assigner une valeur par d√©faut au score si une erreur se produit lors de l'ajustement du mod√®le.\n",
        "- **n_jobs** : nombre de processeurs √† utiliser lors du calcul. -1 signifie qu'on souhaite utiliser tous les processeurs disponibles. Cela peut bloquer le PC le temps de la recherche. Si on veut garder un ou deux processeurs de libres, on peut lui donner un nombre entier qui correspond au nombre de processeurs qu'on souhaite utiliser."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad7b9099-28f2-482e-8efb-13ab59306a21",
      "metadata": {
        "id": "ad7b9099-28f2-482e-8efb-13ab59306a21"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# Fixer la graine al√©atoire pour garantir la reproductibilit√©\n",
        "np.random.seed(2025)\n",
        "\n",
        "# D√©finition de la validation crois√©e\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=2025)\n",
        "\n",
        "# Dictionnaires pour stocker les r√©sultats\n",
        "roc_results = {}\n",
        "pr_results = {}\n",
        "\n",
        "best_models = {}\n",
        "best_overall_model = None\n",
        "best_overall_auroc = 0\n",
        "best_overall_params = None\n",
        "\n",
        "# Optimisation des hyperparam√®tres et calcul des courbes ROC et PR sur la CV\n",
        "for name, info in models.items():\n",
        "    print(f\"üîé Optimisation des hyperparam√®tres pour {name}...\")\n",
        "\n",
        "    # D√©finition du pipeline : standardisation + s√©lection des variables + mod√®le\n",
        "    pipeline = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),  # Normalisation\n",
        "        (\"feature_selection\", SelectKBest(score_func=mutual_info_classif, k=30)),  # S√©lection des variables\n",
        "        (\"clf\", info[\"model\"])  # Mod√®le\n",
        "    ])\n",
        "\n",
        "    # D√©finition des m√©triques utilis√©es dans la recherche sur grille\n",
        "    scoring_metrics = {\"AUROC\": \"roc_auc\", \"AUPRC\": \"average_precision\"}\n",
        "\n",
        "    # Recherche des hyperparam√®tres via GridSearchCV\n",
        "    grid = GridSearchCV(\n",
        "        estimator = pipeline,\n",
        "        param_grid=info[\"params\"],\n",
        "        return_train_score = False,\n",
        "        cv=cv,\n",
        "        scoring=scoring_metrics,\n",
        "        n_jobs=-1,\n",
        "        refit=\"AUROC\"  # Le mod√®le sera r√©ajust√© avec la meilleure configuration selon l'AUROC\n",
        "    )\n",
        "    grid.fit(X_train_res, y_train_res)\n",
        "\n",
        "    # Extraction du mod√®le avec les meilleurs hyperparam√®tres\n",
        "    best_model = grid.best_estimator_\n",
        "    best_params = grid.best_params_\n",
        "\n",
        "    # Stockage des scores moyens de la recherche sur grille\n",
        "    best_auroc = grid.cv_results_[\"mean_test_AUROC\"][grid.best_index_]\n",
        "    best_auprc = grid.cv_results_[\"mean_test_AUPRC\"][grid.best_index_]\n",
        "    best_auroc_std = grid.cv_results_[\"std_test_AUROC\"][grid.best_index_]\n",
        "    best_auprc_std = grid.cv_results_[\"std_test_AUPRC\"][grid.best_index_]\n",
        "\n",
        "    print(f\"‚úî Meilleurs hyperparam√®tres pour {name} : {best_params}\")\n",
        "    print(f\"üìä Score moyen AUROC en CV : {best_auroc:.2f} +/- {best_auroc_std:.2f}\")\n",
        "    print(f\"üìä Score moyen AUPRC en CV : {best_auprc:.2f} +/- {best_auprc_std:.2f}\\n\")\n",
        "\n",
        "    # Stockage du mod√®le et des scores\n",
        "    best_models[name] = (best_model, best_auroc, best_auprc)\n",
        "\n",
        "    # Mise √† jour du meilleur mod√®le global en fonction de l'AUROC\n",
        "    if best_auroc > best_overall_auroc:\n",
        "        best_overall_model = best_model\n",
        "        best_overall_auroc = best_auroc\n",
        "        best_overall_auprc = best_auprc\n",
        "        best_overall_auroc_std = best_auroc_std\n",
        "        best_overall_auprc_std = best_auprc_std\n",
        "        best_overall_params = best_params\n",
        "\n",
        "\n",
        "    pipeline_best = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),  # Normalisation\n",
        "        (\"feature_selection\", SelectKBest(score_func=mutual_info_classif, k=30)),  # S√©lection des variables\n",
        "        (\"clf\", best_model)  # Mod√®le\n",
        "    ])\n",
        "\n",
        "    # Pr√©dictions en validation crois√©e pour tracer les courbes ROC et PR\n",
        "    y_scores = cross_val_predict(pipeline_best, X_train_res, y_train_res, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "\n",
        "    # Calcul des courbes ROC\n",
        "    fpr, tpr, _ = roc_curve(y_train_res, y_scores)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Calcul des courbes Pr√©cision-Rappel\n",
        "    precisions, recalls, _ = precision_recall_curve(y_train_res, y_scores)\n",
        "    pr_auc = auc(recalls, precisions)\n",
        "\n",
        "    # Stockage des r√©sultats pour affichage\n",
        "    roc_results[name] = (fpr, tpr, roc_auc)\n",
        "    pr_results[name] = (recalls, precisions, pr_auc)\n",
        "\n",
        "# Affichage du meilleur mod√®le trouv√©\n",
        "print(f\"üèÜ Meilleur mod√®le global : {best_overall_model.named_steps['clf'].__class__.__name__}\")\n",
        "print(f\"üéØ Hyperparam√®tres optimaux : {best_overall_params}\")\n",
        "print(f\"üìà AUROC moyen en CV : {best_overall_auroc:.2f} +/- {best_overall_auroc_std:.2f}\")\n",
        "\n",
        "# Affichage des courbes ROC pour tous les mod√®les\n",
        "plt.figure(figsize=(10, 6))\n",
        "for name, (fpr, tpr, roc_auc) in roc_results.items():\n",
        "    plt.plot(fpr, tpr, label=f\"{name} (AUROC = {roc_auc:.2f})\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"Taux de faux positifs (1 - sp√©cificit√©)\")\n",
        "plt.ylabel(\"Taux de vrais positifs (rappel)\")\n",
        "plt.title(\"Courbes ROC des mod√®les optimis√©s (Validation Crois√©e)\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Affichage des courbes Pr√©cision-Rappel pour tous les mod√®les\n",
        "plt.figure(figsize=(10, 6))\n",
        "for name, (recalls, precisions, pr_auc) in pr_results.items():\n",
        "    plt.plot(recalls, precisions, label=f\"{name} (AUC PR = {pr_auc:.2f})\")\n",
        "baseline = np.sum(y_train_res) / len(y_train_res)\n",
        "plt.plot([0, 1], [baseline, baseline], linestyle='--', color='grey', label=f\"Baseline AUPRC = {baseline:.2f}\")\n",
        "plt.xlabel(\"Rappel\")\n",
        "plt.ylabel(\"Pr√©cision\")\n",
        "plt.title(\"Courbes Pr√©cision-Rappel des mod√®les optimis√©s (Validation Crois√©e)\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0af8c814-257c-4cad-bbc0-b07706ce9572",
      "metadata": {
        "id": "0af8c814-257c-4cad-bbc0-b07706ce9572"
      },
      "source": [
        " <font size = 7>‚ö†Ô∏è</font>\n",
        "\n",
        " **ne pas utiliser `cross_val_predict` pour choisir un mod√®le**\n",
        "\n",
        " Ici `cross_val_predict` a √©t√© utilis√© uniquement pour illustrer le notebook avec l'affichage des courbes ROC et PR.      \n",
        " Le r√©sultat de `cross_val_predict` peut diff√©rer de celui obtenu avec `cross_val_score` (utilis√© si on n'optimise pas les hyper-param√®tres) ou `GridSearchCV` (surcouche de cross_val_score o√π on va d'abord optimiser les hyper-param√®tres), car les √©l√©ments sont regroup√©s diff√©remment. La fonction `cross_val_score` (ou `GridSearchCV`) calcule un **score moyen** sur les folds de validation crois√©e, tandis que `cross_val_predict` renvoie les **√©tiquettes** (ou probabilit√©s si on pr√©cise : method=\"predict_proba\") pr√©dites sur les folds de validation par plusieurs mod√®les distincts (car entrain√©s sur diff√©rents folds d'entrainement).\n",
        "\n",
        "\n",
        "Lorsqu'on utilise `cross_val_predict` :   \n",
        "1. **On ne capture pas la variabilit√© des performances** observ√©e pendant la validation crois√©e.\n",
        "2. **On risque un surajustement aux donn√©es d'entra√Ænement** si on choisit le mod√®le bas√© uniquement sur `cross_val_predict` plut√¥t que sur les r√©sultats de `GridSearchCV`.\n",
        "\n",
        "Pour comparer les mod√®les entre eux, il faut utiliser leurs **scores moyens** obtenus pendant la **validation crois√©e**, et non sur `cross_val_predict`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1158e3b-a3cd-41e3-a070-95213d344ed7",
      "metadata": {
        "id": "d1158e3b-a3cd-41e3-a070-95213d344ed7"
      },
      "source": [
        "<font size = 7>‚ö†Ô∏è</font>\n",
        "\n",
        "\n",
        "**Valeurs par d√©faut** des fonctions scikit, notamment pour les mod√®les.\n",
        "\n",
        "Pour les mod√®les ML, quand on ne pr√©cise pas la valeur de tous les param√®tres des fonctions scikit, des valeurs par d√©faut sont utilis√©es (elles sont r√©f√©renc√©es dans la documentation li√©e √† la fonction). Cependant, pour s'assurer que notre code soit le plus reproductible possible, il vaut mieux pr√©ciser ces valeurs - m√™me si on garde les valeurs par d√©faut - car **les valeurs par d√©faut utilis√©es par scikit changent avec les versions de scikit**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32e1830a-6ee9-4bf6-860c-8c3e14c5b4ff",
      "metadata": {
        "id": "32e1830a-6ee9-4bf6-860c-8c3e14c5b4ff"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Application </b> Impact sur les performances du mod√®le de la recherche des hyper-param√®tres selon diff√©rentes m√©triques : </div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7022ccb8-f649-4a0e-9b94-c81e31ce6804",
      "metadata": {
        "id": "7022ccb8-f649-4a0e-9b94-c81e31ce6804"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Widget d'affichage des r√©sultats\n",
        "output = widgets.Output()\n",
        "\n",
        "# D√©finition des mod√®les et de leurs hyperparam√®tres\n",
        "models_test = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"model\": LogisticRegression(max_iter=10000, random_state=2025, class_weight=\"balanced\"),\n",
        "        \"params\": {\n",
        "            \"clf__C\": [0.01, 0.1, 1, 10, 100],\n",
        "            \"clf__solver\": [\"liblinear\", \"lbfgs\", \"saga\"]\n",
        "        }\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        \"model\": RandomForestClassifier(random_state=2025, class_weight=\"balanced\"),\n",
        "        \"params\": {\n",
        "            \"clf__n_estimators\": [10, 50, 100, 200],\n",
        "            \"clf__max_depth\": [5, 10, 20]\n",
        "        }\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        \"model\": GradientBoostingClassifier(random_state=2025),\n",
        "        \"params\": {\n",
        "            \"clf__n_estimators\": [50, 100, 200],\n",
        "            \"clf__learning_rate\": [0.01, 0.1, 0.2]\n",
        "        }\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        \"model\": SVC(probability=True, random_state=2025, class_weight=\"balanced\"),\n",
        "        \"params\": {\n",
        "            \"clf__C\": [0.01, 0.1, 1, 10],\n",
        "            \"clf__kernel\": [\"linear\", \"rbf\"]\n",
        "        }\n",
        "    },\n",
        "    \"MLP Classifier\": {\n",
        "        \"model\": MLPClassifier(max_iter=1000, random_state=2025),\n",
        "        \"params\": {\n",
        "            \"clf__hidden_layer_sizes\": [(50,), (100,), (50, 50)],\n",
        "            \"clf__alpha\": [0.0001, 0.001, 0.01, 0.1]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Liste des m√©triques pour l'optimisation des hyper-param√®tres\n",
        "scoring_options = {\n",
        "    \"Accuracy\": \"accuracy\",\n",
        "    \"F1-score\": \"f1\",\n",
        "    \"Rappel\": \"recall\",\n",
        "    \"Pr√©cision\": \"precision\",\n",
        "    \"AUROC\": \"roc_auc\",\n",
        "    \"AUPRC\": \"average_precision\"\n",
        "}\n",
        "\n",
        "# Widgets interactifs\n",
        "model_select = widgets.SelectMultiple(\n",
        "    options=list(models.keys()),\n",
        "    value=[\"Logistic Regression\", \"SVM\"],\n",
        "    description=\"Mod√®les:\"\n",
        ")\n",
        "\n",
        "scoring_select = widgets.SelectMultiple(\n",
        "    options=list(scoring_options.keys()),\n",
        "    value=[\"AUROC\"],\n",
        "    description=\"M√©triques:\",\n",
        "    layout=widgets.Layout(width=\"50%\", height = \"100%\")\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Lancer l'optimisation\")\n",
        "\n",
        "# Fonction d'optimisation et d'affichage des courbes ROC et PR sur une seule figure par mod√®le\n",
        "def optimize_models(b):\n",
        "    with output:\n",
        "        clear_output(wait=True)  # Nettoie l'affichage pr√©c√©dent\n",
        "\n",
        "        selected_models = model_select.value\n",
        "        selected_metrics = {metric: scoring_options[metric] for metric in scoring_select.value}\n",
        "\n",
        "        print(f\"üîé Optimisation des hyperparam√®tres pour {', '.join(selected_models)} en fonction de {', '.join(scoring_select.value)}...\\n\")\n",
        "\n",
        "        # Dictionnaires pour stocker les r√©sultats des courbes\n",
        "        roc_results = {model: {} for model in selected_models}\n",
        "        pr_results = {model: {} for model in selected_models}\n",
        "\n",
        "        for model_name in selected_models:\n",
        "            print(f\"üìå Mod√®le en cours : {model_name}\")\n",
        "\n",
        "            model_info = models_test[model_name]\n",
        "\n",
        "            # D√©finition du pipeline : standardisation + s√©lection des variables + mod√®le\n",
        "            pipeline = Pipeline([\n",
        "                (\"scaler\", StandardScaler()),  # Normalisation\n",
        "                (\"feature_selection\", SelectKBest(score_func=mutual_info_classif, k=30)),  # S√©lection des variables\n",
        "                (\"clf\", model_info[\"model\"])  # Mod√®le\n",
        "            ])\n",
        "\n",
        "            # D√©finition de la validation crois√©e\n",
        "            cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=2025)\n",
        "\n",
        "            # S√©lectionner une m√©trique au hasard pour le refit\n",
        "            refit_metric = np.random.choice(list(selected_metrics.keys()))\n",
        "            # Recherche des hyperparam√®tres via GridSearchCV avec plusieurs m√©triques\n",
        "            grid = GridSearchCV(\n",
        "                pipeline,\n",
        "                param_grid=model_info[\"params\"],\n",
        "                cv=cv,\n",
        "                scoring=selected_metrics,\n",
        "                n_jobs=-1,\n",
        "                refit=refit_metric  # On utilise une seule m√©trique pour le refit\n",
        "            )\n",
        "            grid.fit(X_train_res, y_train_res)\n",
        "            results = grid.cv_results_\n",
        "\n",
        "            # Stocker les meilleurs param√®tres pour chaque m√©trique\n",
        "            best_models = {}\n",
        "            for metric_name, metric in selected_metrics.items():\n",
        "                best_index = np.nonzero(results[f\"rank_test_{metric_name}\"] == 1)[0][0]\n",
        "                best_params = results[\"params\"][best_index]\n",
        "                best_params = {key.replace(\"clf__\", \"\"): value for key, value in best_params.items()}\n",
        "                best_models[metric_name] = model_info[\"model\"].set_params(**best_params)\n",
        "\n",
        "                print(f\"‚úîÔ∏è Meilleurs hyperparam√®tres pour {model_name} ({metric_name}) : {best_params}\")\n",
        "\n",
        "            # G√©n√©ration des courbes ROC et PR pour chaque m√©trique optimis√©e\n",
        "            for metric_name, best_model in best_models.items():\n",
        "                best_pipeline = Pipeline([\n",
        "                    (\"scaler\", StandardScaler()),\n",
        "                    (\"feature_selection\", SelectKBest(score_func=mutual_info_classif, k=30)),\n",
        "                    (\"clf\", best_model)\n",
        "                ])\n",
        "\n",
        "                # Pr√©dictions en validation crois√©e pour la courbe ROC et PR\n",
        "                y_scores = cross_val_predict(best_pipeline, X_train_res, y_train_res, cv=cv, method=\"predict_proba\")[:, 1]\n",
        "\n",
        "                # Calcul des courbes ROC\n",
        "                fpr, tpr, _ = roc_curve(y_train_res, y_scores)\n",
        "                roc_auc = auc(fpr, tpr)\n",
        "\n",
        "                # Calcul des courbes Pr√©cision-Rappel\n",
        "                precisions, recalls, _ = precision_recall_curve(y_train_res, y_scores)\n",
        "                pr_auc = auc(recalls, precisions)\n",
        "\n",
        "                print(f\"üìà AUROC en CV ({metric_name}) : {roc_auc:.2f}\")\n",
        "                print(f\"üìâ AUC PR en CV ({metric_name}) : {pr_auc:.2f}\\n\")\n",
        "\n",
        "                # Stockage des r√©sultats\n",
        "                roc_results[model_name][metric_name] = (fpr, tpr, roc_auc)\n",
        "                pr_results[model_name][metric_name] = (recalls, precisions, pr_auc)\n",
        "\n",
        "        # Affichage des courbes ROC et PR sur une seule figure par mod√®le\n",
        "        for model_name in selected_models:\n",
        "            fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "            # Courbes ROC\n",
        "            for metric_name, (fpr, tpr, roc_auc) in roc_results[model_name].items():\n",
        "                axes[0].plot(fpr, tpr, label=f\"{metric_name} (AUROC = {roc_auc:.2f})\")\n",
        "            axes[0].plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "            axes[0].set_title(f\"Courbes ROC - {model_name}\")\n",
        "            axes[0].legend(loc=\"lower right\")\n",
        "\n",
        "            # Courbes PR\n",
        "            for metric_name, (recalls, precisions, pr_auc) in pr_results[model_name].items():\n",
        "                axes[1].plot(recalls, precisions, label=f\"{metric_name} (AUC PR = {pr_auc:.2f})\")\n",
        "            baseline = np.sum(y_train_res) / len(y_train_res)\n",
        "            axes[1].plot([0, 1], [baseline, baseline], linestyle='--', color='grey', label=f\"Baseline AUPRC = {baseline:.2f}\")\n",
        "            axes[1].set_title(f\"Courbes PR - {model_name}\")\n",
        "            axes[1].legend(loc=\"lower left\")\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "# Lier la fonction au bouton\n",
        "button.on_click(optimize_models)\n",
        "display(model_select, scoring_select, button, output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86cb0385-7b92-4560-abdb-1da95490e753",
      "metadata": {
        "id": "86cb0385-7b92-4560-abdb-1da95490e753"
      },
      "source": [
        "## üîÆ 6.3 Pr√©dictions du meilleur mod√®le sur les donn√©es tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f42ab125-7094-4917-aea1-3b1e95909d08",
      "metadata": {
        "id": "f42ab125-7094-4917-aea1-3b1e95909d08"
      },
      "outputs": [],
      "source": [
        "# Fixer la graine al√©atoire pour garantir la reproductibilit√©\n",
        "np.random.seed(2025)\n",
        "\n",
        "# === Pr√©dictions sur les donn√©es test avec le meilleur mod√®le ===\n",
        "model_final = best_overall_model.set_params(**best_overall_params).fit(X_train_res, y_train_res)\n",
        "y_test_scores = model_final.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "# Calcul des m√©triques sur les donn√©es test\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_scores)\n",
        "roc_auc_test = auc(fpr_test, tpr_test)\n",
        "\n",
        "precisions_test, recalls_test, _ = precision_recall_curve(y_test, y_test_scores)\n",
        "pr_auc_test = auc(recalls_test, precisions_test)\n",
        "\n",
        "# Affichage des r√©sultats sur les donn√©es test\n",
        "print(f\"\\nüî¨ R√©sultats sur les donn√©es d'entrainement :\")\n",
        "print(f\"üìä AUROC sur train : {best_overall_auroc:.2f}\")\n",
        "print(f\"üìä AUPRC sur train : {best_overall_auprc:.2f}\")\n",
        "\n",
        "print(f\"\\nüî¨ R√©sultats sur les donn√©es test :\")\n",
        "print(f\"üìä AUROC sur test : {roc_auc_test:.2f}\")\n",
        "print(f\"üìä AUPRC sur test : {pr_auc_test:.2f}\")\n",
        "\n",
        "# === Affichage des courbes ROC et PR ===\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Courbe ROC\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(fpr_test, tpr_test, label=f\"AUROC = {roc_auc_test:.2f}\", color=\"blue\")\n",
        "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
        "plt.xlabel(\"Taux de faux positifs (1 - sp√©cificit√©)\")\n",
        "plt.ylabel(\"Taux de vrais positifs (rappel)\")\n",
        "plt.title(f\"Courbe ROC - {best_overall_model.named_steps['clf'].__class__.__name__}\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "\n",
        "# Courbe Pr√©cision-Rappel\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(recalls_test, precisions_test, label=f\"AUPRC = {pr_auc_test:.2f}\", color=\"green\")\n",
        "baseline = np.sum(y_test) / len(y_test)\n",
        "plt.plot([0, 1], [baseline, baseline], linestyle='--', color='grey', label=f\"Baseline AUPRC = {baseline:.2f}\")\n",
        "plt.xlabel(\"Rappel\")\n",
        "plt.ylabel(\"Pr√©cision\")\n",
        "plt.title(f\"Courbe Pr√©cision-Rappel - {best_overall_model.named_steps['clf'].__class__.__name__}\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03295f04-7ccc-41b5-9d02-0aebcb664892",
      "metadata": {
        "id": "03295f04-7ccc-41b5-9d02-0aebcb664892"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Application </b> Impact du seuil de d√©cision sur le rappel et la pr√©cision : </div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e25729f-b732-4bb6-82cf-6ab7c349c63f",
      "metadata": {
        "id": "9e25729f-b732-4bb6-82cf-6ab7c349c63f"
      },
      "outputs": [],
      "source": [
        "# G√©n√©rer les probabilit√©s pr√©dictives pour la classe positive sur les donn√©es test\n",
        "model_final = best_overall_model.set_params(**best_overall_params).fit(X_train_res, y_train_res)\n",
        "y_test_scores = model_final.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# D√©finition du widget interactif pour ajuster le seuil de d√©cision\n",
        "threshold_slider = widgets.FloatSlider(\n",
        "    value=0.5,  # Seuil initial √† 0.5\n",
        "    min=0.0,\n",
        "    max=1.0,\n",
        "    step=0.01,\n",
        "    description=\"Seuil\",\n",
        "    continuous_update=False\n",
        ")\n",
        "\n",
        "# Widget d'affichage des r√©sultats\n",
        "output = widgets.Output()\n",
        "\n",
        "def update_threshold(threshold):\n",
        "    \"\"\"Met √† jour la pr√©cision et le rappel en fonction du seuil s√©lectionn√©.\"\"\"\n",
        "    with output:\n",
        "        output.clear_output(wait=True)  # Nettoie l'affichage pr√©c√©dent\n",
        "\n",
        "        # Appliquer le seuil pour g√©n√©rer les pr√©dictions binaires\n",
        "        y_pred_thresholded = (y_test_scores >= threshold).astype(int)\n",
        "\n",
        "        # Calcul des m√©triques avec gestion des erreurs\n",
        "        precision = precision_score(y_test, y_pred_thresholded, zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred_thresholded)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred_thresholded).ravel()\n",
        "        specificity = tn / (tn+fp)\n",
        "        # Affichage des r√©sultats\n",
        "        print(\"\\033[1m\" + f\"üîπ Seuil de d√©cision : {threshold:.2f} \" + \"\\033[0m\" + f\"-> On consid√®re que la pr√©diction appartient √† la classe positive si sa probabilit√© est sup√©rieur √† {threshold*100:.0f} %\")\n",
        "        print(\" \")\n",
        "        print(\"\\033[1m\" + \"cas 1Ô∏è‚É£ : on veut pr√©dire les CQ qui passent pour ne pas les mesurer.\"+ \"\\033[0m\")\n",
        "        print(\" \")\n",
        "        print(\"‚û°Ô∏è Objectif : maximiser la sp√©cificit√© et minimiser le taux d'√©chec (1-sensiblit√©)\")\n",
        "        print(f\"üî∏ Sp√©cificit√© : {specificity:.2f} -> {specificity*100:.0f}% des arcs pass sont correctement d√©tect√©s comme pass\")\n",
        "        print(\"\\033[1m\" + f\"üî∏ Taux d'√©chec : {1-recall:.2f} ->  {100-recall*100:.0f}%  des arcs fail sont d√©tect√©s comme pass\"+ \"\\033[0m\")\n",
        "        print(\" \")\n",
        "        print(\"\\033[1m\" +\"cas 2Ô∏è‚É£ : on veut pr√©dire les CQ qui ne passent pas pour r√©optimiser les plans d'embl√©e.\"+ \"\\033[0m\")\n",
        "        print(\" \")\n",
        "        print(\"‚û°Ô∏è Objectif : maximiser la sensibilit√© et minimiser le taux de fausses d√©couvertes (1-pr√©cision)\")\n",
        "        print(f\"üî∏ Rappel/sensibilit√© : {recall:.2f} ->  {recall*100:.0f}% des arcs fail sont correctement d√©tect√©s comme fail\")\n",
        "        print(\"\\033[1m\" + f\"üî∏ Taux de fausses d√©couvertes : {1-precision:.2f} -> {100-precision*100:.0f}% des arcs pr√©dits fail ne le sont pas\"+ \"\\033[0m\")\n",
        "\n",
        "        # Trac√© des courbes Pr√©cision et Rappel en fonction du seuil\n",
        "        thresholds = np.linspace(0, 1, 100)\n",
        "        precisions = [precision_score(y_test, (y_test_scores >= t).astype(int), zero_division=0) for t in thresholds]\n",
        "        recalls = [recall_score(y_test, (y_test_scores >= t).astype(int)) for t in thresholds]\n",
        "\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(thresholds, precisions, label=\"Pr√©cision\", color=\"blue\")\n",
        "        plt.plot(thresholds, recalls, label=\"Rappel\", color=\"green\")\n",
        "        plt.axvline(threshold, color=\"red\", linestyle=\"--\", label=f\"Seuil = {threshold:.2f}\")\n",
        "        plt.xlabel(\"Seuil de d√©cision\")\n",
        "        plt.ylabel(\"Valeur\")\n",
        "        plt.title(\"Impact du seuil de d√©cision sur la pr√©cision et le rappel\")\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "# Lier le widget au callback\n",
        "widgets.interactive(update_threshold, threshold=threshold_slider)\n",
        "\n",
        "# Affichage des widgets\n",
        "display(threshold_slider, output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9f423cd-f9e7-4d43-948c-d95d762e638f",
      "metadata": {
        "id": "c9f423cd-f9e7-4d43-948c-d95d762e638f"
      },
      "source": [
        "## üîπ 6.4. Interpr√©ter le mod√®le"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0802aa37-3b77-40ae-9172-27e7e3d480a5",
      "metadata": {
        "id": "0802aa37-3b77-40ae-9172-27e7e3d480a5"
      },
      "source": [
        "La <font size = 3> **Permutation Importance** </font>est une technique permettant d'√©valuer l'importance des variables dans un mod√®le de Machine Learning en mesurant l'effet de la permutation al√©atoire de chaque variable sur la performance du mod√®le.\n",
        "\n",
        "<font size = 4> ‚öôÔ∏è **Comment √ßa marche ?** </font>\n",
        "1. **Calcul du score initial** : On √©value la performance du mod√®le sur les donn√©es de test avec les valeurs originales des variables.\n",
        "2. **Permutation d'une variable** : On remplace al√©atoirement les valeurs d'une seule variable tout en gardant les autres inchang√©es.\n",
        "3. **Calcul du nouveau score** : On mesure la performance du mod√®le avec cette variable perturb√©e.\n",
        "4. **Impact sur la performance** :\n",
        "   - Si la permutation d'une variable **r√©duit** la performance, cela signifie qu'elle est **importante** pour les pr√©dictions.\n",
        "   - Si l'impact est **faible ou n√©gatif**, cela indique que la variable est **peu informative** voire nuisible.\n",
        "\n",
        "<font size = 4> üìä **Interpr√©tation**</font>   \n",
        "- **Valeur positive √©lev√©e** ‚Üí Variable fortement contributive.\n",
        "- **Valeur proche de z√©ro** ‚Üí Variable non influente.\n",
        "- **Valeur n√©gative** ‚Üí La variable ajoute du bruit et nuit √† la pr√©diction.\n",
        "\n",
        "<font size = 4> ‚úÖ **Avantages**</font>   \n",
        "‚úîÔ∏è Simple √† comprendre et interpr√©ter.  \n",
        "‚úîÔ∏è Compatible avec n'importe quel mod√®le de Machine Learning.  \n",
        "\n",
        "<font size = 4> ‚ùó **Limitations**</font>   \n",
        "‚ö†Ô∏è Peut √™tre biais√© en pr√©sence de variables fortement corr√©l√©es.  \n",
        "‚ö†Ô∏è Co√ªt de calcul √©lev√© pour les grands ensembles de donn√©es.  \n",
        "\n",
        "\n",
        "‚ÑπÔ∏è D'autres m√©thodes existent. Elles sont d√©crites dans la documentation scikit : üîó [Documentation Scikit - Model Inspection](https://scikit-learn.org/stable/inspection.html#inspection)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "674f4238-4fe7-4d8b-87ff-92c7b1cdfce7",
      "metadata": {
        "id": "674f4238-4fe7-4d8b-87ff-92c7b1cdfce7"
      },
      "outputs": [],
      "source": [
        "# Fixer la graine al√©atoire pour garantir la reproductibilit√© des r√©sultats\n",
        "np.random.seed(2025)\n",
        "\n",
        "# S√©lectionner les indices des variables qui ont √©t√© retenues apr√®s la s√©lection par information mutuelle\n",
        "selected_features_idx = model_final.named_steps[\"feature_selection\"].get_support(indices=True)\n",
        "\n",
        "# R√©cup√©rer les noms des variables s√©lectionn√©es en utilisant leurs indices\n",
        "selected_features = X_test.columns[selected_features_idx]  # Liste des noms des variables retenues\n",
        "\n",
        "# Calcul de l'importance permutation sur les donn√©es de test\n",
        "# L'importance permutation mesure l'impact de chaque variable en permutant ses valeurs et en observant\n",
        "# la diminution de la performance du mod√®le (ici, l'AUROC). Plus la baisse de performance est grande, plus\n",
        "# la variable est importante pour la pr√©diction.\n",
        "\n",
        "result_test = permutation_importance(\n",
        "    model_final,  # Mod√®le entra√Æn√©\n",
        "    X_test,       # Donn√©es test\n",
        "    y_test,       # Labels test\n",
        "    scoring=\"roc_auc\",  # Mesure de performance utilis√©e : AUROC (aire sous la courbe ROC)\n",
        "    n_repeats=100,  # Nombre de permutations effectu√©es pour chaque variable\n",
        "    random_state=2025,  # Fixation du g√©n√©rateur al√©atoire pour reproductibilit√©\n",
        "    n_jobs=-1  # Utilisation de tous les c≈ìurs disponibles pour acc√©l√©rer le calcul\n",
        ")\n",
        "\n",
        "# Ordonner les variables en fonction de leur importance d√©croissante\n",
        "# Les variables avec la plus grande importance seront affich√©es en haut du graphique.\n",
        "sorted_importances_idx = result_test.importances_mean.argsort()\n",
        "\n",
        "# Cr√©ation d'un DataFrame contenant les valeurs d'importance permutation pour chaque variable\n",
        "importances_test = pd.DataFrame(\n",
        "    result_test.importances[sorted_importances_idx].T,  # Transposition pour format adapt√©\n",
        "    columns=X_test.columns  # Attribution des noms des variables\n",
        ")\n",
        "\n",
        "# Affichage des r√©sultats sous forme de boxplot\n",
        "plt.figure(figsize=(30, 30))\n",
        "\n",
        "# D√©finition des propri√©t√©s de la ligne m√©diane du boxplot\n",
        "medianprops = dict(color=\"black\", linewidth=1)\n",
        "\n",
        "# Cr√©ation du boxplot pour les variables s√©lectionn√©es\n",
        "importances_test[selected_features].plot.box(\n",
        "    whis=10,  # √âtendue des moustaches (10 signifie 10 fois l'√©cart interquartile)\n",
        "    vert=False,  # Affichage horizontal des bo√Ætes\n",
        "    fontsize=12,  # Taille de la police\n",
        "    patch_artist=True,  # Remplissage des bo√Ætes avec une couleur\n",
        "    boxprops=dict(facecolor='orange'),  # Couleur des bo√Ætes\n",
        "    whiskerprops=dict(color='black'),  # Couleur des moustaches\n",
        "    medianprops=medianprops  # Application des propri√©t√©s d√©finies pour la m√©diane\n",
        ")\n",
        "\n",
        "# Ajout d'un titre au graphique\n",
        "plt.title(\"Permutation Importance (Test Set)\", fontsize=14)\n",
        "\n",
        "# Ajout d'une ligne verticale pour indiquer la r√©f√©rence √† 0 (absence d'impact)\n",
        "plt.axvline(x=0, color=\"k\", linestyle=\"--\")\n",
        "\n",
        "# √âtiquetage de l'axe X\n",
        "plt.xlabel(\"Diminution du score AUROC\", fontsize=12)\n",
        "\n",
        "# Affichage d'une grille pour am√©liorer la lisibilit√©\n",
        "plt.grid(visible=True)\n",
        "\n",
        "# Ajustement automatique de la mise en page pour √©viter le chevauchement des √©l√©ments\n",
        "plt.tight_layout()\n",
        "# Affichage du graphique\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "059af579-262d-46ee-8dcd-e73ced21c977",
      "metadata": {
        "id": "059af579-262d-46ee-8dcd-e73ced21c977"
      },
      "outputs": [],
      "source": [
        "# Calcul de la moyenne des importances permutation pour chaque variable\n",
        "mean_importances = importances_test[selected_features].mean()\n",
        "\n",
        "# Filtrer les variables dont la moyenne d'importance est > 0.01\n",
        "selected_vars = mean_importances[mean_importances > 0.02]\n",
        "\n",
        "# Affichage des r√©sultats\n",
        "if not selected_vars.empty:\n",
        "    print(\"Variables avec une importance permutation moyenne > 0.02 :\")\n",
        "    print(selected_vars.sort_values(ascending=False))\n",
        "else:\n",
        "    print(\"Aucune variable avec une importance sup√©rieure √† 0.02\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c96d41e-24e5-424e-a367-a37d184bb677",
      "metadata": {
        "id": "4c96d41e-24e5-424e-a367-a37d184bb677"
      },
      "source": [
        "## üîπ 6.5 Se comparer avec une m√©thode plus simple"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1194653f-6a55-4152-9448-a22afb105c9f",
      "metadata": {
        "id": "1194653f-6a55-4152-9448-a22afb105c9f"
      },
      "source": [
        "üîç On va comparer les performances du mod√®le sur les donn√©es test avec l'utilisation d'un **simple seuil** sur les deux variables les plus importantes pour le mod√®le."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f502ebbf-6fe4-4ca2-b2e8-e779d3100f03",
      "metadata": {
        "id": "f502ebbf-6fe4-4ca2-b2e8-e779d3100f03"
      },
      "outputs": [],
      "source": [
        "# R√©cup√©ration des deux variables les plus importantes d'apr√®s la permutation importance\n",
        "top_features = importances_test.mean().sort_values(ascending=False).head(2).index\n",
        "print(\"Deux variables les plus importantes :\", top_features.tolist())\n",
        "\n",
        "# Pr√©diction des probabilit√©s avec le mod√®le final\n",
        "y_scores_model = model_final.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcul des courbes ROC et PR pour le mod√®le final\n",
        "fpr_model, tpr_model, _ = roc_curve(y_test, y_scores_model)\n",
        "roc_auc_model = auc(fpr_model, tpr_model)\n",
        "precision_model, recall_model, _ = precision_recall_curve(y_test, y_scores_model)\n",
        "pr_auc_model = auc(recall_model, precision_model)\n",
        "\n",
        "# Cr√©ation des figures pour les courbes ROC et PR\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Courbe ROC\n",
        "axes[0].plot(fpr_model, tpr_model, label=f\"Mod√®le Final (AUROC = {roc_auc_model:.2f})\", color=\"blue\")\n",
        "\n",
        "# Courbe Pr√©cision-Rappel\n",
        "axes[1].plot(recall_model, precision_model, label=f\"Mod√®le Final (AUC PR = {pr_auc_model:.2f})\", color=\"blue\")\n",
        "\n",
        "# Boucle pour afficher les courbes ROC et PR des variables individuelles\n",
        "for feature in top_features:\n",
        "    X_test_feature = X_test_std[feature]  # S√©lection de la variable\n",
        "\n",
        "    # V√©rification de l'orientation de la courbe ROC et inversion si n√©cessaire\n",
        "    fpr_feature, tpr_feature, _ = roc_curve(y_test, X_test_feature)\n",
        "    if auc(fpr_feature, tpr_feature) < 0.5:  # Si l'AUC est < 0.5, inverser les valeurs\n",
        "        X_test_feature = -X_test_feature\n",
        "        fpr_feature, tpr_feature, _ = roc_curve(y_test, X_test_feature)\n",
        "\n",
        "    # Calcul des scores\n",
        "    roc_auc_feature = auc(fpr_feature, tpr_feature)\n",
        "    precision_feature, recall_feature, _ = precision_recall_curve(y_test, X_test_feature)\n",
        "    pr_auc_feature = auc(recall_feature, precision_feature)\n",
        "\n",
        "    # Ajout de la courbe ROC\n",
        "    axes[0].plot(fpr_feature, tpr_feature, linestyle=\"dashed\", label=f\"{feature} (AUROC = {roc_auc_feature:.2f})\")\n",
        "\n",
        "    # Ajout de la courbe PR\n",
        "    axes[1].plot(recall_feature, precision_feature, linestyle=\"dashed\", label=f\"{feature} (AUC PR = {pr_auc_feature:.2f})\")\n",
        "\n",
        "# Personnalisation des courbes ROC\n",
        "axes[0].plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Baseline AUROC = 0.5\")\n",
        "axes[0].set_xlabel(\"Taux de Faux Positifs (FPR)\")\n",
        "axes[0].set_ylabel(\"Taux de Vrais Positifs (TPR)\")\n",
        "axes[0].set_title(\"Courbes ROC - Mod√®le vs Variables Individuelles\")\n",
        "axes[0].legend()\n",
        "axes[0].grid()\n",
        "\n",
        "# Personnalisation des courbes PR\n",
        "baseline = np.sum(y_test) / len(y_test)\n",
        "axes[1].plot([0, 1], [baseline, baseline], linestyle='--', color='grey', label=f\"Baseline AUPRC = {baseline:.2f}\")\n",
        "axes[1].set_xlabel(\"Rappel\")\n",
        "axes[1].set_ylabel(\"Pr√©cision\")\n",
        "axes[1].set_title(\"Courbes PR - Mod√®le vs Variables Individuelles\")\n",
        "axes[1].legend()\n",
        "axes[1].grid()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bacc1b3-74b6-4b8e-b02d-0216b3595238",
      "metadata": {
        "id": "8bacc1b3-74b6-4b8e-b02d-0216b3595238"
      },
      "source": [
        "## üíæ Sauvegarder son mod√®le"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f35b6351-1d48-4420-80a4-ecbed0c28756",
      "metadata": {
        "id": "f35b6351-1d48-4420-80a4-ecbed0c28756"
      },
      "source": [
        "Enregistrer un mod√®le cr√©√© avec scikit-learn est une √©tape importante pour pouvoir le **r√©utiliser** sans avoir √† le r√©entra√Æner."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a55bec35-fa7a-4d35-aa27-72333acaaa35",
      "metadata": {
        "id": "a55bec35-fa7a-4d35-aa27-72333acaaa35"
      },
      "source": [
        "<font size = 4> **1. Joblib** </font>\n",
        "\n",
        "<font size = 3> ‚úî **Avantages :**</font>\n",
        "\n",
        "\n",
        "- Optimis√© pour les objets volumineux et les mod√®les scikit-learn (utilisation efficace de la compression et du multi-processing).\n",
        "- Plus rapide que `pickle` pour sauvegarder et charger des mod√®les de grande taille.\n",
        "- Permet de s√©rialiser des numpy arrays de mani√®re plus efficace.\n",
        "\n",
        "<font size = 3> ‚ùå **Inconv√©nients :**</font>\n",
        "\n",
        "\n",
        "- Sp√©cifique √† Python et donc **non compatible avec Microsoft .NET** ou d'autres langages.\n",
        "- Ne garantit pas la compatibilit√© entre diff√©rentes versions de Python ou de scikit-learn.\n",
        "- Ne supporte pas bien le transfert entre syst√®mes d‚Äôexploitation diff√©rents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46c990a4-e8c5-43a5-8acf-f64bd7c2d235",
      "metadata": {
        "id": "46c990a4-e8c5-43a5-8acf-f64bd7c2d235"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Pr√©diction des probabilit√©s avec le mod√®le final\n",
        "# Utilise le mod√®le final pour pr√©dire les probabilit√©s sur l'ensemble de test\n",
        "# `predict_proba` renvoie un tableau de probabilit√©s pour chaque classe, nous prenons la probabilit√© de la classe positive (1)\n",
        "y_scores_model = model_final.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcul des courbes ROC et PR pour le mod√®le final\n",
        "fpr_model, tpr_model, _ = roc_curve(y_test, y_scores_model)\n",
        "roc_auc_model_base = auc(fpr_model, tpr_model)\n",
        "print(f\"AUROC du mod√®le de base : {roc_auc_model_base:.2f}\")\n",
        "\n",
        "# Enregistrer le mod√®le avec joblib\n",
        "# `joblib.dump` enregistre le mod√®le dans un fichier binaire\n",
        "# Cela permet de sauvegarder l'√©tat du mod√®le pour une utilisation ult√©rieure\n",
        "joblib.dump(model_final, 'model_final.joblib')\n",
        "\n",
        "# Charger le mod√®le avec joblib\n",
        "# `joblib.load` charge le mod√®le √† partir du fichier binaire\n",
        "# Cela permet de restaurer l'√©tat du mod√®le pour faire des pr√©dictions\n",
        "joblib_model = joblib.load('model_final.joblib')\n",
        "\n",
        "# Faire des pr√©dictions sur X_test avec le mod√®le charg√©\n",
        "# Utilise le mod√®le charg√© pour pr√©dire les probabilit√©s sur l'ensemble de test\n",
        "# `predict_proba` renvoie un tableau de probabilit√©s pour chaque classe, nous prenons la probabilit√© de la classe positive (1)\n",
        "proba_joblib = joblib_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# √âvaluer les performances du mod√®le charg√©\n",
        "# Calcul des courbes ROC et PR pour le mod√®le charg√©\n",
        "fpr_model, tpr_model, _ = roc_curve(y_test, proba_joblib)\n",
        "roc_auc_model = auc(fpr_model, tpr_model)\n",
        "\n",
        "print(f\"AUROC du mod√®le charg√© : {roc_auc_model:.2f}\")\n",
        "\n",
        "# Comparaison directe des pr√©dictions\n",
        "# Calcul de la diff√©rence moyenne entre les probabilit√©s pr√©dites par le mod√®le original et le mod√®le charg√©\n",
        "# Cela permet de v√©rifier que les pr√©dictions sont coh√©rentes entre les deux mod√®les\n",
        "differences = np.abs(y_scores_model - proba_joblib)\n",
        "print(f\"Diff√©rence moyenne entre les pr√©dictions : {np.mean(differences):.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3be8d242-6697-419c-991e-84293228723d",
      "metadata": {
        "id": "3be8d242-6697-419c-991e-84293228723d"
      },
      "source": [
        "<font size = 4> **2. ONNX** </font>\n",
        "\n",
        "<font size = 3> ‚úî **Avantages :**</font>\n",
        "\n",
        "\n",
        "- **Ind√©pendant du langage** : ONNX permet d'exporter des mod√®les qui peuvent √™tre utilis√©s avec **Python, C++, Java, Microsoft .NET (via ML.NET), et bien d'autres**.\n",
        "- Supporte les **frameworks de deep learning** (PyTorch, TensorFlow, scikit-learn via `skl2onnx`).\n",
        "- Compatible avec **Microsoft .NET (ML.NET)**, facilitant l‚Äôint√©gration des mod√®les dans le TPS Eclipse par exemple.\n",
        "\n",
        "<font size = 3> ‚ùå **Inconv√©nients :**</font>\n",
        "\n",
        "\n",
        "- Conversion plus complexe, tous les mod√®les ne sont pas directement compatibles (ex : certains mod√®les scikit-learn n√©cessitent une conversion avec `skl2onnx`).\n",
        "- Moins flexible que Joblib pour charger un mod√®le et continuer son entra√Ænement.\n",
        "- Peut n√©cessiter une adaptation sp√©cifique du code pour le chargement et l'utilisation du mod√®le.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b19c3b-9723-41d4-81cb-11da409bc4c0",
      "metadata": {
        "id": "c9b19c3b-9723-41d4-81cb-11da409bc4c0"
      },
      "outputs": [],
      "source": [
        "#Pour installer onnxruntime dans colab\n",
        "!pip install onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ff9e93-11f8-443a-9202-c8f67395d79f",
      "metadata": {
        "id": "07ff9e93-11f8-443a-9202-c8f67395d79f"
      },
      "outputs": [],
      "source": [
        "import onnxruntime as rt\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "from skl2onnx import convert_sklearn\n",
        "\n",
        "# Pr√©diction des probabilit√©s avec le mod√®le scikit-learn\n",
        "# Utilise le mod√®le final pour pr√©dire les probabilit√©s sur l'ensemble de test\n",
        "# `predict_proba` renvoie un tableau de probabilit√©s pour chaque classe, nous prenons la probabilit√© de la classe positive (1)\n",
        "y_scores_model = model_final.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calcul de l'AUROC pour le mod√®le scikit-learn\n",
        "roc_auc_model_base = roc_auc_score(y_test, y_scores_model)\n",
        "print(f\"AUROC du mod√®le de base : {roc_auc_model_base:.2f}\")\n",
        "\n",
        "# Conversion du mod√®le scikit-learn en format ONNX\n",
        "# `convert_sklearn` convertit un mod√®le scikit-learn en un mod√®le ONNX\n",
        "# `FloatTensorType` sp√©cifie le type de donn√©es d'entr√©e attendu par le mod√®le ONNX\n",
        "model_onnx = convert_sklearn(\n",
        "    model_final,\n",
        "    initial_types=[('input', FloatTensorType([None, X_test.shape[1]]))],\n",
        "    target_opset=12\n",
        ")\n",
        "\n",
        "# Fonction pour sauvegarder le mod√®le ONNX dans un fichier\n",
        "def save_model(model, filename):\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(model.SerializeToString())\n",
        "\n",
        "# Sauvegarde du mod√®le ONNX dans un fichier\n",
        "save_model(model_onnx, 'model_final.onnx')\n",
        "\n",
        "# Conversion des donn√©es de test en tableau numpy de type float32\n",
        "# ONNX Runtime attend des entr√©es de type float32\n",
        "X_test_np = X_test.astype(np.float32).to_numpy()\n",
        "\n",
        "# Chargement du mod√®le ONNX avec ONNX Runtime\n",
        "sess = rt.InferenceSession(\"model_final.onnx\")\n",
        "\n",
        "# R√©cup√©ration des noms des entr√©es et sorties du mod√®le ONNX\n",
        "input_name = sess.get_inputs()[0].name\n",
        "label_name = sess.get_outputs()[0].name\n",
        "label_proba = sess.get_outputs()[1].name\n",
        "\n",
        "# Pr√©diction des labels avec le mod√®le ONNX\n",
        "# `run` ex√©cute le mod√®le ONNX et renvoie les pr√©dictions\n",
        "pred_onx = sess.run([label_name], {input_name: X_test_np.astype(np.float32)})[0]\n",
        "\n",
        "# Pr√©diction des probabilit√©s avec le mod√®le ONNX\n",
        "# `run` ex√©cute le mod√®le ONNX et renvoie les probabilit√©s\n",
        "proba_onx = sess.run([label_proba], {input_name: X_test_np.astype(np.float32)})[0]\n",
        "\n",
        "# Extraction des probabilit√©s pour la classe positive (1)\n",
        "proba_onx = [d[1] for d in proba_onx]\n",
        "\n",
        "# Calcul de l'AUROC pour le mod√®le ONNX\n",
        "# Comparaison des probabilit√©s pr√©dites par le mod√®le ONNX avec les vraies √©tiquettes\n",
        "roc_auc_model_onnx = roc_auc_score(y_test, proba_onx)\n",
        "print(f\"AUROC du mod√®le ONNX : {roc_auc_model_onnx:.2f}\")\n",
        "\n",
        "# Comparaison directe des pr√©dictions entre le mod√®le scikit-learn et le mod√®le ONNX\n",
        "# Calcul de la diff√©rence moyenne entre les probabilit√©s pr√©dites par les deux mod√®les\n",
        "# Cela permet de v√©rifier que les pr√©dictions sont coh√©rentes entre les deux mod√®les\n",
        "differences = np.abs(y_scores_model - proba_onx)\n",
        "print(f\"Diff√©rence moyenne entre les pr√©dictions : {np.mean(differences):.6f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9966276-f63a-43c1-8823-5446efa2750e",
      "metadata": {
        "id": "a9966276-f63a-43c1-8823-5446efa2750e"
      },
      "source": [
        "\n",
        "\n",
        "‚û° **Si vous travaillez exclusivement en Python** et avec des mod√®les scikit-learn, `Joblib` est le meilleur choix.  \n",
        "‚û° **Si vous devez d√©ployer un mod√®le dans un environnement .NET** ou tout autre langage, `ONNX` est recommand√©.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94dd2525-4d03-4b38-b0e9-6a10a46075fd",
      "metadata": {
        "id": "94dd2525-4d03-4b38-b0e9-6a10a46075fd"
      },
      "source": [
        "<font size = 7>‚ö†Ô∏è</font>\n",
        "\n",
        "\n",
        "Toujours s'assurer que les pr√©dictions du mod√®les de base python et du mod√®le enregistr√© sont les m√™mes. Des diff√©rences peuvent apparaitre, notamment avec ONNX, si on ne d√©finit pas correctement les param√®tres d'enregistrement ou d'import."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}